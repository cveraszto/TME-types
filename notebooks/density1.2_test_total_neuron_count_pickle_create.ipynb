{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85958d86-4317-4cb5-bc35-9b3c852ac8a7",
   "metadata": {},
   "source": [
    "We create a pickle file fom csv files\n",
    "- dict of dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d35228a-83b7-4248-b6e7-abfbe3a2d17d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import copy\n",
    "from voxcell import RegionMap\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3eb1e842-6998-4e9d-a340-e5c1e775b974",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/gpfs/bbp.cscs.ch/data/project/proj84/csaba/aibs_10x_mouse_wholebrain/notebooks/scripts/')\n",
    "\n",
    "from helper_functions import get_all_filenames, get_csv_filenames, extract_prefix_from_filenames\n",
    "from helper_functions import extract_regions_from_column_names, read_and_concat_csv_files_new, combine_rows_and_calculate_average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "902f9b59-8091-4a39-bba4-e3e163584562",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of memberships at all levels: 3489\n",
      "number of memberships at substructure level: 737\n"
     ]
    }
   ],
   "source": [
    "#Get all substructure volume data\n",
    "file =  '/gpfs/bbp.cscs.ch/data/project/proj84/csaba/aibs_10x_mouse_wholebrain/metadata/parcellation_to_parcellation_term_membership_extend.csv'\n",
    "parcellation_annotation = pd.read_csv(file)\n",
    "print(\"number of memberships at all levels:\",len(parcellation_annotation))\n",
    "parcellation_annotation = parcellation_annotation[parcellation_annotation['parcellation_term_set_name'] == 'substructure'] \n",
    "print(\"number of memberships at substructure level:\",len(parcellation_annotation))\n",
    "volumes = parcellation_annotation[['parcellation_label', 'parcellation_index', 'parcellation_term_acronym', 'parcellation_term_set_name', 'parcellation_term_name', 'voxel_count', 'volume_mm3']]\n",
    "substructure_vol = volumes[volumes['parcellation_term_set_name'] == 'substructure']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4a56465-3b54-43dd-8345-4d96a70380a9",
   "metadata": {},
   "source": [
    "I have a df column volumes['parcellation_term_acronym'] where I want to remove all / from every element if it's part of the string. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "67222991-6305-46a9-adf3-63aedaf3a7d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = '/gpfs/bbp.cscs.ch/data/project/proj84/csaba/aibs_10x_mouse_wholebrain/results/density_calculations/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6c8e80a3-75d6-49ac-8a95-118a1d18419b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper_functions import get_nrrd_files\n",
    "\n",
    "save_nrrd = f'{folder}nrrd/'\n",
    "filenames = get_all_filenames(folder)\n",
    "\n",
    "created_nrrds, nrrd_files_without_extension = get_nrrd_files(save_nrrd)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c9f72950-47cc-4314-9afb-ae0bf1a96827",
   "metadata": {},
   "source": [
    "#Test which nrrd file is missing from step 2:\n",
    "def get_nrrd_files(folder_path):\n",
    "    \"\"\"\n",
    "    Get NRRD files from a folder and return the file names with and without extensions.\n",
    "\n",
    "    Parameters:\n",
    "    - folder_path: Path to the folder containing NRRD files.\n",
    "\n",
    "    Returns:\n",
    "    - nrrd_files: List of NRRD file names.\n",
    "    - nrrd_files_without_extension: List of NRRD file names without extensions.\n",
    "    \"\"\"\n",
    "    # Get all files in the folder\n",
    "    files = os.listdir(folder_path)\n",
    "\n",
    "    # Filter files with the .nrrd extension\n",
    "    nrrd_files = [file for file in files if file.endswith('.nrrd')]\n",
    "\n",
    "    # Get NRRD file names without extension\n",
    "    nrrd_files_without_extension = [file_name[:-5] for file_name in nrrd_files]\n",
    "\n",
    "    return nrrd_files, nrrd_files_without_extension\n",
    "\n",
    "\n",
    "save_nrrd = f'{folder}nrrd/'\n",
    "filenames = get_all_filenames(folder)\n",
    "\n",
    "created_nrrds, nrrd_files_without_extension = get_nrrd_files(save_nrrd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0161ef65-7ed1-471e-8ca8-8f8578a6c938",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "# Pattern to match the numeric part of filenames\n",
    "pattern = re.compile(r'(\\d{4})')  # Matches four consecutive digits\n",
    "\n",
    "# Set to store existing numbers\n",
    "existing_numbers = set()\n",
    "\n",
    "for filename in nrrd_files_without_extension:\n",
    "    # Match numeric part of filename\n",
    "    match = pattern.search(filename)\n",
    "    if match:\n",
    "        existing_numbers.add(int(match.group(1)))\n",
    "\n",
    "# Find missing numbers between 1 and 5300\n",
    "missing_numbers = sorted(set(range(1, 5323)) - existing_numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3eca8929-9538-4384-b820-13e5454f24c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5322"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check the number of cell types which do not have an nrrd file\n",
    "len(missing_numbers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "143ec5e0-eaa4-492f-82ce-8886e3a0670d",
   "metadata": {},
   "source": [
    "### Continuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6469c5e5-0459-4475-8e83-1895ccaf3796",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.86 s, sys: 111 ms, total: 1.98 s\n",
      "Wall time: 2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Get all regional density data\n",
    "folder_path = f'{folder}csv/'\n",
    "filenames = get_all_filenames(folder_path)\n",
    "csv_filenames = get_csv_filenames(folder_path)\n",
    "prefixes = extract_prefix_from_filenames(csv_filenames)\n",
    "unique_prefixes = sorted(list(set(prefixes)))\n",
    "#The next line is different because unique_prefixes is different than how Allen named cell types\n",
    "allen_regions = extract_regions_from_column_names(folder_path, csv_filenames)\n",
    "result_dataframes = read_and_concat_csv_files_new(csv_filenames, unique_prefixes, folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c1bad0ea-ec25-4317-a8ee-21fe27434851",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Update result_dataframes with the real cell type names\n",
    "result_dataframes = {allen_regions[i]: df for i, (_, df) in enumerate(result_dataframes.items())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fe543286-70ea-4dac-a148-7456960e81f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_result_dataframes = combine_rows_and_calculate_average(result_dataframes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c1570cb-c0cb-4438-ab3b-e63842a376c0",
   "metadata": {},
   "source": [
    "- I have a dict of dfs (result_dataframes) where result_dataframes.keys() contains all region names. Each df contains a column of density numbers e.g. result_dataframes['AAA']['concatenated_density']\n",
    "- There are no duplicate cell-types in the dfs\n",
    "- I need to calculate volume from appropriate annotation volume voxels (what was used in step 2 script)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59b36110-9fb3-448d-b671-6c18a819610d",
   "metadata": {},
   "source": [
    "We will continue with calculating the total cells in the brain using cell-type densities and region volumes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a1118a32-225e-4a32-8020-e09fa961c263",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nrrd, json\n",
    "#Read CCFv3 annotation volumes (choose 1)\n",
    "# Specify the full or relative path to the log file\n",
    "# #1\n",
    "# data_folder = \"/gpfs/bbp.cscs.ch/project/proj84/piluso/share/general/warped_augmented_CCFv3/\"\n",
    "# CCFv3_0, _ = nrrd.read(f'{data_folder}annotation_25_2022_CCFv3_0.nrrd')\n",
    "# #2\n",
    "# data_folder = \"/gpfs/bbp.cscs.ch/data/project/proj62/csaba/atlas/bbp_prod_files/2022/\"\n",
    "# CCFv3_0, _ = nrrd.read(f'{data_folder}annotation_25.nrrd')\n",
    "# #3\n",
    "data_folder = \"/gpfs/bbp.cscs.ch/project/proj84/piluso/share/general/warped_augmented_CCFv3/\"\n",
    "CCFv3_0, _ = nrrd.read(f'{data_folder}annotation_25_2022_CCFv3a.nrrd')\n",
    "# CCFv3_0, _ = nrrd.read(\"/gpfs/bbp.cscs.ch/data/project/proj84/atlas_pipeline_runs/2024-05-15T22:44:26+02:00/annotation_ccfv3_l23split_barrelsplit_validated.nrrd\")\n",
    "\n",
    "#region_map_path ='/gpfs/bbp.cscs.ch/project/proj62/csaba/atlas/bbp_prod_files/1.json'\n",
    "region_map_path = '/gpfs/bbp.cscs.ch/data/project/proj84/atlas_pipeline_runs/2024-05-15T22:44:26+02:00/hierarchy_ccfv3_l23split_barrelsplit.json'\n",
    "region_map = RegionMap.load_json(region_map_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bdf2392b-2ece-4c79-a3ef-2fda3ee8e8ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Volume of the voxel in mm^3: 1.5625e-05\n",
      "Volume of the voxel in mm^3: 1e-06\n"
     ]
    }
   ],
   "source": [
    "# Edge length of the voxel in millimeters\n",
    "edge_length_mm = 25.0 / 1000.0  # Convert micrometers to millimeters\n",
    "\n",
    "# Calculate the volume of the voxel in cubic millimeters\n",
    "volume25_mm3 = round(edge_length_mm ** 3, 10)\n",
    "\n",
    "print(\"Volume of the voxel in mm^3:\", volume25_mm3)\n",
    "\n",
    "# Edge length of the voxel in millimeters\n",
    "edge_length_mm = 10.0 / 1000.0  # Convert micrometers to millimeters\n",
    "\n",
    "# Calculate the volume of the voxel in cubic millimeters\n",
    "volume10_mm3 = round(edge_length_mm ** 3, 10)\n",
    "\n",
    "print(\"Volume of the voxel in mm^3:\", volume10_mm3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db90d666-9596-4756-b5ea-ddae6a56ab4f",
   "metadata": {},
   "source": [
    "From density we calculate total number of cells: density * volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "16e90841-16c9-4d60-a2e6-6e788fba43c8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "annotation vol is 25 um resolution but it is larger than the vanilla CCFv3\n",
      "CPU times: user 50.1 s, sys: 10.5 s, total: 1min\n",
      "Wall time: 1min\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "total_cells = {}\n",
    "\n",
    "if CCFv3_0.shape == (528, 320, 456):\n",
    "    print(\"annotation vol is 25 um resolution\")\n",
    "    for region_name, df in combined_result_dataframes.items():\n",
    "        # Get the corresponding volume for the region\n",
    "        label = volumes.loc[volumes['parcellation_term_acronym'] == region_name, 'parcellation_label'].values[0]\n",
    "        id_ = int(label.rsplit('-', 1)[-1])\n",
    "        #id_ = region_map.find(region_name, attr='name', ignore_case=True, with_descendants=False)\n",
    "        volume = np.count_nonzero(CCFv3_0 == id_) * volume25_mm3\n",
    "        #print(region_name, label, id_, f\"{volume:.6f}\")\n",
    "        # Calculate total cells by multiplying density by volume\n",
    "        total_cells[region_name] = pd.DataFrame({'total_cellnumber': df['density_mm3'] * volume})\n",
    "\n",
    "elif CCFv3_0.shape == (566, 320, 456):\n",
    "    print(\"annotation vol is 25 um resolution but it is larger than the vanilla CCFv3\")\n",
    "    for region_name, df in combined_result_dataframes.items():\n",
    "        # Get the corresponding volume for the region\n",
    "        label = volumes.loc[volumes['parcellation_term_acronym'] == region_name, 'parcellation_label'].values[0]\n",
    "        id_ = int(label.rsplit('-', 1)[-1])\n",
    "        #id_ = region_map.find(region_name, attr='name', ignore_case=True, with_descendants=False)\n",
    "        volume = np.count_nonzero(CCFv3_0 == id_) * volume25_mm3\n",
    "        #print(region_name, label, id_, f\"{volume:.6f}\")\n",
    "        # Calculate total cells by multiplying density by volume\n",
    "        total_cells[region_name] = pd.DataFrame({'total_cellnumber': df['density_mm3'] * volume})\n",
    "\n",
    "elif CCFv3_0.shape == (1320, 800, 1140) or CCFv3_0.shape == (1140, 800, 1320):\n",
    "    print(\"*** annotation vol is 10 um resolution *** \")\n",
    "    for region_name, df in combined_result_dataframes.items():\n",
    "        # Get the corresponding volume for the region\n",
    "        label = volumes.loc[volumes['parcellation_term_acronym'] == region_name, 'parcellation_label'].values[0]\n",
    "        id_ = int(label.rsplit('-', 1)[-1])\n",
    "        #id_ = region_map.find(region_name, attr='name', ignore_case=True, with_descendants=False)\n",
    "        #print(region_name, label, id_)\n",
    "        \n",
    "        if CCFv3_0.shape == (1320, 800, 1140):\n",
    "            volume = np.count_nonzero(CCFv3_0 == id_) * volume10_mm3\n",
    "        elif CCFv3_0.shape == (1140, 800, 1320):\n",
    "            volume = np.count_nonzero(CCFv3_0 == id_) * volume10_mm3 \n",
    "        # Calculate total cells by multiplying density by volume\n",
    "        print(region_name, label, id_, f\"{volume:.6f}\")\n",
    "        total_cells[region_name] = pd.DataFrame({'total_cellnumber': df['density_mm3'] * volume})\n",
    "else:\n",
    "    print(\"*** Annotation volume shape is not understood. *** \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "023cc33b-4157-456a-bed7-c159fec7b2f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved here: /gpfs/bbp.cscs.ch/data/project/proj84/csaba/aibs_10x_mouse_wholebrain/results/density_calculations/\n"
     ]
    }
   ],
   "source": [
    "# Assuming 'total_cells' is your dictionary of DataFrames\n",
    "with open(f'{folder}total_cells.pickle', 'wb') as f:\n",
    "    pickle.dump(total_cells, f)\n",
    "\n",
    "print(f\"Saved here: {folder}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "62d3c274-e9e2-4ca4-9eae-e022bf60adca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a new dictionary to store the sums for each region\n",
    "collapsed_data = {region: df['total_cellnumber'].sum() for region, df in total_cells.items()}\n",
    "\n",
    "# Create a new DataFrame from the collapsed_data dictionary\n",
    "collapsed_df = pd.DataFrame.from_dict(collapsed_data, orient='index', columns=['sum_concatenated_density'])\n",
    "\n",
    "# Reset the index to make the region names a column instead of the index\n",
    "collapsed_df.reset_index(inplace=True)\n",
    "\n",
    "# Rename the columns to match the desired output\n",
    "collapsed_df.columns = ['region_name', 'SUM_of_Cells']\n",
    "\n",
    "# Convert 'sum_concatenated_density' column values to integers\n",
    "collapsed_df['SUM_of_Cells'] = collapsed_df['SUM_of_Cells'].astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4780fece-6465-42a2-9d23-133c0e698842",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total sum of cells: 93,876,733\n"
     ]
    }
   ],
   "source": [
    "# Print the total sum of cells in a human-readable format\n",
    "print(\"Total sum of cells:\", '{:,.0f}'.format(collapsed_df['SUM_of_Cells'].sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd9fe906-cf20-48fa-94b9-9cb598edb4a2",
   "metadata": {},
   "source": [
    "## Neuron / non-neuron ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "57e940d3-cb3c-4782-9853-c367e16285ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_path = \"/gpfs/bbp.cscs.ch/data/project/proj84/csaba/aibs_10x_mouse_wholebrain/metadata/WMB-10X/20231215/views/cell_metadata_with_cluster_annotation.csv\"\n",
    "metadata = pd.read_csv(meta_path,  usecols=['class', 'cluster'], dtype={'cell_label':str})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dc355439-a22f-4148-9ae5-6d002ab5576c",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = ['01 IT-ET Glut', '02 NP-CT-L6b Glut', '03 OB-CR Glut',\n",
    "       '04 DG-IMN Glut', '05 OB-IMN GABA', '06 CTX-CGE GABA',\n",
    "       '07 CTX-MGE GABA', '08 CNU-MGE GABA', '09 CNU-LGE GABA',\n",
    "       '10 LSX GABA', '11 CNU-HYa GABA', '12 HY GABA', '13 CNU-HYa Glut',\n",
    "       '14 HY Glut', '15 HY Gnrh1 Glut', '16 HY MM Glut', '17 MH-LH Glut',\n",
    "       '18 TH Glut', '19 MB Glut', '20 MB GABA', '21 MB Dopa',\n",
    "       '22 MB-HB Sero', '23 P Glut', '24 MY Glut', '25 Pineal Glut',\n",
    "       '26 P GABA', '27 MY GABA', '28 CB GABA', '29 CB Glut',]\n",
    "\n",
    "nn_classes = ['30 Astro-Epen', '31 OPC-Oligo', '32 OEC', '33 Vascular',\n",
    "       '34 Immune']\n",
    "\n",
    "exc = ['01 IT-ET Glut', '02 NP-CT-L6b Glut', '03 OB-CR Glut',\n",
    "      '04 DG-IMN Glut', '13 CNU-HYa Glut', '14 HY Glut', '15 HY Gnrh1 Glut', '16 HY MM Glut', '17 MH-LH Glut',\n",
    "      '18 TH Glut', '19 MB Glut', '23 P Glut', '24 MY Glut', '25 Pineal Glut', '29 CB Glut',]\n",
    "inh = ['05 OB-IMN GABA', '06 CTX-CGE GABA', '07 CTX-MGE GABA', '08 CNU-MGE GABA', '09 CNU-LGE GABA',\n",
    "      '10 LSX GABA', '11 CNU-HYa GABA', '12 HY GABA', '20 MB GABA', '26 P GABA', '27 MY GABA', '28 CB GABA', ]\n",
    "other = ['21 MB Dopa', '22 MB-HB Sero', ]\n",
    "\n",
    "neurontypes = np.unique(metadata[metadata['class'].isin(n_classes)]['cluster'].values)\n",
    "nonneurontypes = np.unique(metadata[metadata['class'].isin(nn_classes)]['cluster'].values)\n",
    "exctypes = np.unique(metadata[metadata['class'].isin(exc)]['cluster'].values)\n",
    "inhtypes = np.unique(metadata[metadata['class'].isin(inh)]['cluster'].values)\n",
    "othertypes = np.unique(metadata[metadata['class'].isin(other)]['cluster'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "19e184cd-dbe3-40d6-9353-50b1bc657619",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_cells_copy = copy.deepcopy(total_cells)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "07d33360-44d4-4047-90c4-99829149ba64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total sum of non-neurons: 41,341,793\n"
     ]
    }
   ],
   "source": [
    "total_cells_copy = copy.deepcopy(total_cells) \n",
    "\n",
    "for key, df in total_cells_copy.items():\n",
    "    total_cells_copy[key] = df[df.index.isin(nonneurontypes)]\n",
    "    \n",
    "# Create a new dictionary to store the sums for each region\n",
    "collapsed_data = {region: df['total_cellnumber'].sum() for region, df in total_cells_copy.items()}\n",
    "\n",
    "# Create a new DataFrame from the collapsed_data dictionary\n",
    "collapsed_df = pd.DataFrame.from_dict(collapsed_data, orient='index', columns=['sum_concatenated_density'])\n",
    "\n",
    "# Reset the index to make the region names a column instead of the index\n",
    "collapsed_df.reset_index(inplace=True)\n",
    "\n",
    "# Rename the columns to match the desired output\n",
    "collapsed_df.columns = ['region_name', 'SUM_of_Cells']\n",
    "\n",
    "# Convert 'sum_concatenated_density' column values to integers\n",
    "collapsed_df['SUM_of_Cells'] = collapsed_df['SUM_of_Cells'].astype(int)\n",
    "\n",
    "# Print the total sum of cells in a human-readable format\n",
    "print(\"Total sum of non-neurons:\", '{:,.0f}'.format(collapsed_df['SUM_of_Cells'].sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "691505fe-9f68-41de-bc19-e6f0738b85dd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total sum of neurons: 52,534,615\n"
     ]
    }
   ],
   "source": [
    "total_cells_copy = copy.deepcopy(total_cells) \n",
    "\n",
    "for key, df in total_cells_copy.items():\n",
    "    total_cells_copy[key] = df[df.index.isin(neurontypes)]\n",
    "    \n",
    "# Create a new dictionary to store the sums for each region\n",
    "collapsed_data = {region: df['total_cellnumber'].sum() for region, df in total_cells_copy.items()}\n",
    "\n",
    "# Create a new DataFrame from the collapsed_data dictionary\n",
    "collapsed_df = pd.DataFrame.from_dict(collapsed_data, orient='index', columns=['sum_concatenated_density'])\n",
    "\n",
    "# Reset the index to make the region names a column instead of the index\n",
    "collapsed_df.reset_index(inplace=True)\n",
    "\n",
    "# Rename the columns to match the desired output\n",
    "collapsed_df.columns = ['region_name', 'SUM_of_Cells']\n",
    "\n",
    "# Convert 'sum_concatenated_density' column values to integers\n",
    "collapsed_df['SUM_of_Cells'] = collapsed_df['SUM_of_Cells'].astype(int)\n",
    "\n",
    "# Print the total sum of cells in a human-readable format\n",
    "print(\"Total sum of neurons:\", '{:,.0f}'.format(collapsed_df['SUM_of_Cells'].sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "31d71371-2b5f-41df-81bf-5ec335510af5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total sum of excitatory neurons: 30,757,245\n"
     ]
    }
   ],
   "source": [
    "total_cells_copy = copy.deepcopy(total_cells) \n",
    "\n",
    "for key, df in total_cells_copy.items():\n",
    "    total_cells_copy[key] = df[df.index.isin(exctypes)]\n",
    "    \n",
    "# Create a new dictionary to store the sums for each region\n",
    "collapsed_data = {region: df['total_cellnumber'].sum() for region, df in total_cells_copy.items()}\n",
    "\n",
    "# Create a new DataFrame from the collapsed_data dictionary\n",
    "collapsed_df = pd.DataFrame.from_dict(collapsed_data, orient='index', columns=['sum_concatenated_density'])\n",
    "\n",
    "# Reset the index to make the region names a column instead of the index\n",
    "collapsed_df.reset_index(inplace=True)\n",
    "\n",
    "# Rename the columns to match the desired output\n",
    "collapsed_df.columns = ['region_name', 'SUM_of_Cells']\n",
    "\n",
    "# Convert 'sum_concatenated_density' column values to integers\n",
    "collapsed_df['SUM_of_Cells'] = collapsed_df['SUM_of_Cells'].astype(int)\n",
    "\n",
    "# Print the total sum of cells in a human-readable format\n",
    "print(\"Total sum of excitatory neurons:\", '{:,.0f}'.format(collapsed_df['SUM_of_Cells'].sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1f88a82d-031a-4804-8c6e-0fdbed41e0f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total sum of inhibitory neurons: 21,605,821\n"
     ]
    }
   ],
   "source": [
    "total_cells_copy = copy.deepcopy(total_cells) \n",
    "\n",
    "for key, df in total_cells_copy.items():\n",
    "    total_cells_copy[key] = df[df.index.isin(inhtypes)]\n",
    "    \n",
    "# Create a new dictionary to store the sums for each region\n",
    "collapsed_data = {region: df['total_cellnumber'].sum() for region, df in total_cells_copy.items()}\n",
    "\n",
    "# Create a new DataFrame from the collapsed_data dictionary\n",
    "collapsed_df = pd.DataFrame.from_dict(collapsed_data, orient='index', columns=['sum_concatenated_density'])\n",
    "\n",
    "# Reset the index to make the region names a column instead of the index\n",
    "collapsed_df.reset_index(inplace=True)\n",
    "\n",
    "# Rename the columns to match the desired output\n",
    "collapsed_df.columns = ['region_name', 'SUM_of_Cells']\n",
    "\n",
    "# Convert 'sum_concatenated_density' column values to integers\n",
    "collapsed_df['SUM_of_Cells'] = collapsed_df['SUM_of_Cells'].astype(int)\n",
    "\n",
    "# Print the total sum of cells in a human-readable format\n",
    "print(\"Total sum of inhibitory neurons:\", '{:,.0f}'.format(collapsed_df['SUM_of_Cells'].sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e2f301c6-7e8c-48b6-9471-6db3ba32a472",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total sum of modulatory neurons: 171,163\n"
     ]
    }
   ],
   "source": [
    "total_cells_copy = copy.deepcopy(total_cells) \n",
    "\n",
    "for key, df in total_cells_copy.items():\n",
    "    total_cells_copy[key] = df[df.index.isin(othertypes)]\n",
    "    \n",
    "# Create a new dictionary to store the sums for each region\n",
    "collapsed_data = {region: df['total_cellnumber'].sum() for region, df in total_cells_copy.items()}\n",
    "\n",
    "# Create a new DataFrame from the collapsed_data dictionary\n",
    "collapsed_df = pd.DataFrame.from_dict(collapsed_data, orient='index', columns=['sum_concatenated_density'])\n",
    "\n",
    "# Reset the index to make the region names a column instead of the index\n",
    "collapsed_df.reset_index(inplace=True)\n",
    "\n",
    "# Rename the columns to match the desired output\n",
    "collapsed_df.columns = ['region_name', 'SUM_of_Cells']\n",
    "\n",
    "# Convert 'sum_concatenated_density' column values to integers\n",
    "collapsed_df['SUM_of_Cells'] = collapsed_df['SUM_of_Cells'].astype(int)\n",
    "\n",
    "# Print the total sum of cells in a human-readable format\n",
    "print(\"Total sum of modulatory neurons:\", '{:,.0f}'.format(collapsed_df['SUM_of_Cells'].sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c9a4fe-1c4c-4218-bbd3-825deb277a08",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (cell2loc_env)",
   "language": "python",
   "name": "cell2loc_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
