{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2a663ae-e8d1-459c-a491-3d63e916e284",
   "metadata": {},
   "source": [
    "In this notebook we loop through all MERFISH cells and add a new metadata to them: their region information and its estimated volume in the slice. \n",
    "So if a cell sits in the MOB we calculate the intersected volume of the MOB in the respective slice (with slice position)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f345309b-ff92-4c29-8349-c2846b418d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e63e9ce5-16de-4f36-9c0b-a08f807257e2",
   "metadata": {},
   "source": [
    "Load all cells from the 53 MERFISH slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84e4148e-cece-4340-a30f-ab0311955f92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3739961, 37)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "view_directory = '/gpfs/bbp.cscs.ch/data/project/proj84/csaba/aibs_10x_mouse_wholebrain/metadata/MERFISH-C57BL6J-638850-CCF/20231215/views/'\n",
    "file = os.path.join( view_directory, 'cell_metadata_with_parcellation_annotation.csv')\n",
    "#Load all spatial data into 1 dataframe\n",
    "cell_joined = pd.read_csv(file)\n",
    "cell_joined.set_index('cell_label',inplace=True)\n",
    "cell_joined.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "847b4ddd-f6cd-4d42-8272-56ca919e1fd5",
   "metadata": {},
   "source": [
    "Remove those 15 cells with no x y z CCF coordinates and no parcellation assigments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1fbae783-2674-4d01-8958-8d9626d99e61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3739946, 37)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cell_joined = cell_joined[~((cell_joined['x_ccf'] == 0) & (cell_joined['y_ccf'] == 0) & (cell_joined['z_ccf'] == 0))]\n",
    "cell_joined.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e611a7cb-fd6a-455a-be70-1d9121ddcf96",
   "metadata": {},
   "source": [
    "Create a new smaller df to add additional metadata to the cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "afeff102-0fe8-4bc7-afe9-91c49d153ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To avoid altering the original DataFrame, create a copy first\n",
    "cells = pd.DataFrame()\n",
    "cells = cell_joined[['brain_section_label', 'x_reconstructed', 'y_reconstructed', 'z_reconstructed']].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c4b686aa-21ed-4988-9928-a98f93a81d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform element-wise division TO calculate template number accordingo to Allen tutorial\n",
    "cells.loc[:, 'template_nr'] = cells.loc[:, 'z_reconstructed'].values / 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0eae5fa2-9aa6-4332-a0d3-7a25f1bf0897",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Round the 'template_nr' column to the nearest integer\n",
    "cells.loc[:, 'template_nr'] = cells['template_nr'].round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3a6cd762-9a16-46fc-beae-7fdaa397cb6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3739946, 5), (3739946, 37))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cells.shape, cell_joined.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c787e9d3-e24a-4090-bcb5-59b20cdcc6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cells.loc[:, 'parcellation_substructure'] = cell_joined.loc[:, 'parcellation_substructure']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d6ae942-4ad1-48bc-ba21-c25d1792347e",
   "metadata": {},
   "source": [
    "\n",
    "Template number is the way to slice the warped volume. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "98a39b56-d61f-483a-b2c3-b1b201a142f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# file = '/gpfs/bbp.cscs.ch/data/project/proj84/csaba/aibs_10x_mouse_wholebrain/metadata/Allen-CCF-2020/20230630/parcellation_to_parcellation_term_membership.csv'\n",
    "file = '/gpfs/bbp.cscs.ch/data/project/proj84/csaba/aibs_10x_mouse_wholebrain/metadata/parcellation_to_parcellation_term_membership_extend.csv'\n",
    "\n",
    "parcellation_annotation = pd.read_csv(file)\n",
    "parcellation_indexes = list(np.unique(cell_joined['parcellation_index']))\n",
    "description_of_all_indexes = parcellation_annotation[parcellation_annotation['parcellation_index'].isin(parcellation_indexes)]\n",
    "substructure_info = description_of_all_indexes[description_of_all_indexes['parcellation_term_set_name'] == 'substructure'] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "749d2cd7-61ae-4034-8950-f16a2e1f16fe",
   "metadata": {},
   "source": [
    "We can look up the region_id of each parcellation substructure (for each cell) which is hidden in the 'parcellation_label'.\n",
    "This cell will run 3M times, so it's a bit slow. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "37825bc5-525b-405a-a377-32901832fe05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 22min 9s, sys: 340 ms, total: 22min 10s\n",
      "Wall time: 22min 10s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "def get_region_id(substructure):\n",
    "    region_id = int(substructure_info[substructure_info['parcellation_term_acronym'] == substructure]['parcellation_label'].values[0].split('-')[-1])\n",
    "    return region_id\n",
    "\n",
    "\n",
    "#Create region ids for every parcellation substructure for every cell\n",
    "cells['region_id'] = cells['parcellation_substructure'].apply(lambda x: get_region_id(x))\n",
    "\n",
    "view_directory = '/gpfs/bbp.cscs.ch/data/project/proj84/csaba/aibs_10x_mouse_wholebrain/results/nmi_scores/'\n",
    "file = os.path.join( view_directory, 'temp.csv' )\n",
    "cells.to_csv(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e5db5448-e8f8-4ad8-92ef-81bd44e9c984",
   "metadata": {},
   "outputs": [],
   "source": [
    "#If you don't want to run the previous cell\n",
    "view_directory = '/gpfs/bbp.cscs.ch/data/project/proj84/csaba/aibs_10x_mouse_wholebrain/results/nmi_scores/'\n",
    "file = os.path.join( view_directory, 'temp.csv' )\n",
    "cells = pd.read_csv( file, index_col='cell_label' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7f36dfff-781f-4d6c-a014-c6c47be298f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset the index of cells before merging\n",
    "cells.reset_index(drop=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "02bffe69-991b-42ce-a17f-318c0a60adde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge cells with substructure_info based on 'parcellation_substructure' in cells and 'parcellation_term_acronym' in substructure_info\n",
    "cells = cells.merge(substructure_info[['parcellation_term_acronym', 'parcellation_term_name']], \n",
    "                        left_on='parcellation_substructure', \n",
    "                        right_on='parcellation_term_acronym', \n",
    "                        how='left')\n",
    "\n",
    "# Drop the redundant column 'parcellation_term_acronym'\n",
    "cells.drop(columns=['parcellation_term_acronym'], inplace=True)\n",
    "\n",
    "# Set back the original index of cells\n",
    "cells.set_index('cell_label', inplace=True)  # Replace 'original_index_column_name' with the name of the original index column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c5234fb9-9b85-492a-9ccf-c0f2498a8ba5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3791571, 8)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cells.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a6e7f581-a12d-4078-814d-b9931badb014",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Round the values in the 'template_nr' column to integers and assign back to the column\n",
    "cells['template_nr'] = np.round(cells['template_nr']).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c242f3e0-a639-49bb-8291-0996790ebac2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pickle file.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "# Load the pickle file with the volumes of each region id at every slice (dict of dict)\n",
    "file_directory = '/gpfs/bbp.cscs.ch/data/project/proj84/csaba/aibs_10x_mouse_wholebrain/results/nmi_scores/'\n",
    "file = os.path.join( file_directory, 'template_with_regids.pickle' )\n",
    "\n",
    "#Load region id volumes from volume_calc_from_template.ipynb\n",
    "with open(file, 'rb') as pickle_file:\n",
    "    template_with_regids = pickle.load(pickle_file)\n",
    "\n",
    "print(\"Loaded pickle file.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a99b78e-e8cc-4135-9849-8e417fa60937",
   "metadata": {},
   "source": [
    "Placeholder for fixing key error problem\n",
    "\n",
    "Solutions: these come from parcellation_annotation[parcellation_annotation['parcellation_term_acronym'] has multiple solutions\n",
    "- 229 > 794\n",
    "- 326 > (812, 850,) 866\n",
    "- 956 > 579"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "12e3a726-4d32-4ddd-8d10-37a49015ca76",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 'voxel_vol' column does not contain any NaN values.\n"
     ]
    }
   ],
   "source": [
    "key_errors = []\n",
    "templ_errors = []\n",
    "\n",
    "def get_voxel_vol(row):\n",
    "    template_nr = row['template_nr']\n",
    "    region_id = row['region_id']\n",
    "    try:\n",
    "        return template_with_regids[template_nr][region_id]\n",
    "    except KeyError:\n",
    "\n",
    "        key_errors.append(region_id)\n",
    "        templ_errors.append(template_nr)\n",
    "        # Define mappings for swapping region_id values\n",
    "        mappings = {229: 794, 326: [812, 850, 866], 956: 579}\n",
    "        # Attempt swapping the region_id\n",
    "        if region_id in mappings:\n",
    "            new_region_ids = mappings[region_id]\n",
    "            if isinstance(new_region_ids, list):  # Handle multiple mappings\n",
    "                for new_region_id in new_region_ids:\n",
    "                    try:\n",
    "                        return template_with_regids[template_nr][new_region_id]\n",
    "                    except KeyError:\n",
    "                        #print(f\"Key combination not found: template {template_nr}, region_id {region_id}, or new_region_id {new_region_id}\")\n",
    "                        pass  # Continue to the next mapping if the current one fails\n",
    "            else:\n",
    "                try:\n",
    "                    return template_with_regids[template_nr][new_region_ids]\n",
    "                except KeyError:\n",
    "                    #print(f\"Multi Key combination not found: template {template_nr}, region_id {region_id}, or new_region_id {new_region_ids}\")\n",
    "                    pass  # Continue to the next mapping if the current one fails\n",
    "        \n",
    "        # If all mappings fail, return None\n",
    "        print(f\"Multi Key combination not found: template {template_nr}, region_id {region_id}, or new_region_id {new_region_ids}\")\n",
    "        return None # Return None if key combination not found\n",
    "\n",
    "# Apply the function to create the new column 'voxel_vol'\n",
    "cells['voxel_vol'] = cells.apply(get_voxel_vol, axis=1)\n",
    "\n",
    "\n",
    "#Now there shold not be any np.nan values in the cell voxel vol columns\n",
    "# Check if 'voxel_vol' column has any NaN values\n",
    "has_nan = cells['voxel_vol'].isna().any()\n",
    "\n",
    "if has_nan:\n",
    "    print(\"The 'voxel_vol' column contains NaN values.\")\n",
    "else:\n",
    "    print(\"The 'voxel_vol' column does not contain any NaN values.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85b189e5-a35b-47f3-b019-f4b40140d740",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Region ids and region id volumes on slices\n",
    "Next to Template ids we can add best position along the cortical axis give the nmi estimation between annotation volumes. In positions we have every / more slices, not just the ones which overcame Quality Control. \n",
    "\n",
    "Move this up in the notebook otherwise it won't be saved (not essential) - we don't need this information in the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "808fde6b-a88d-4136-9b48-148d8a119ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "csv_file_path = \"/gpfs/bbp.cscs.ch/data/project/proj84/csaba/aibs_10x_mouse_wholebrain/results/nmi_scores/average_template_array/output.csv\"\n",
    "positions = pd.read_csv(csv_file_path)\n",
    "\n",
    "# Initialize an empty NumPy array to store the first numbers\n",
    "first_numbers_array = np.array([], dtype=float)\n",
    "\n",
    "# Iterate over each string in the list\n",
    "for s in positions['10um_cortical_pos']:\n",
    "    # Parse the string into a list\n",
    "    numbers = ast.literal_eval(s)\n",
    "    # Get the first number\n",
    "    first_number = numbers[0]\n",
    "    # Append the first number to the NumPy array\n",
    "    first_numbers_array = np.append(first_numbers_array, first_number)\n",
    "    \n",
    "positions.loc[:, 'best_pos'] = first_numbers_array\n",
    "positions.loc[:, 'template_nr'] = [string.split('_')[3] for string in positions['X_as_first_dim']]\n",
    "#np.sort(np.unique(positions.template_nr))\n",
    "positions.loc[:, 'template_nr'] = positions.loc[:, 'template_nr'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ad3f123a-bcd9-4f3a-90c5-5c68bf2c0691",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary from the 'best_pos' and 'template_nr' columns in the positions DataFrame\n",
    "pos_dict = dict(zip(positions['template_nr'], positions['best_pos']))\n",
    "\n",
    "# Initialize an array to store the corresponding 'best_pos' values for each 'template_nr' value in cells\n",
    "best_pos_array = []\n",
    "\n",
    "# Loop through all values of cells.loc[:, 'template_nr']\n",
    "for template_nr in cells.loc[:, 'template_nr']:\n",
    "    # Look up the 'best_pos' value for the current 'template_nr' value in the dictionary\n",
    "    best_pos_value = pos_dict.get(template_nr)\n",
    "    # Add the 'best_pos' value to the array\n",
    "    best_pos_array.append(best_pos_value)\n",
    "    #print(best_pos_value)\n",
    "\n",
    "# Convert the array to a numpy array if needed\n",
    "best_pos_array = np.array(best_pos_array)\n",
    "\n",
    "# Overwrite the 'best_position' column in the cells DataFrame with the array\n",
    "cells.loc[:, 'best_position'] = best_pos_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "99839bb2-0591-4bfd-b4bc-81416415b94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "view_directory = '/gpfs/bbp.cscs.ch/data/project/proj84/csaba/aibs_10x_mouse_wholebrain/results/nmi_scores/'\n",
    "file = os.path.join( view_directory, 'cells_in_respective_volumes.csv')\n",
    "cells.to_csv(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27829c6a-56f3-40ae-802a-7850e7d6007e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (cell2loc_env)",
   "language": "python",
   "name": "cell2loc_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
