{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "48f6735e-a824-47db-b070-11949078f255",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/gpfs/bbp.cscs.ch/data/project/proj84/csaba/git/cellden/bin/python\n",
      "2.2.1\n",
      "3.12.2 | packaged by Anaconda, Inc. | (main, Feb 27 2024, 17:35:02) [GCC 11.2.0]\n",
      "/gpfs/bbp.cscs.ch/data/project/proj84/csaba/git/cellden/lib/python3.12/site-packages/pandas/__init__.py\n"
     ]
    }
   ],
   "source": [
    "#Newer pickle versions are not compatible\n",
    "!which python\n",
    "import pandas as pd\n",
    "print(pd.__version__)\n",
    "import sys\n",
    "print(sys.version)\n",
    "import inspect\n",
    "print(inspect.getfile(pd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2ed2ff2-1d06-41b2-99f5-8e12233ed1ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import nrrd\n",
    "import multiprocessing as mp\n",
    "import re, os, copy\n",
    "from voxcell import RegionMap\n",
    "import ast\n",
    "\n",
    "import sys\n",
    "sys.path.append('/gpfs/bbp.cscs.ch/data/project/proj84/csaba/aibs_10x_mouse_wholebrain/notebooks/scripts/')\n",
    "\n",
    "from helper_functions import get_all_filenames, get_csv_filenames, extract_prefix_from_filenames, read_and_concat_csv_files_new, combine_rows_and_calculate_average, create_combined_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "800cc217-9414-44d5-bcf6-f273f7faee85",
   "metadata": {},
   "outputs": [],
   "source": [
    "download_base = '/gpfs/bbp.cscs.ch/data/project/proj84/csaba/aibs_10x_mouse_wholebrain/'\n",
    "root_folder = f\"{download_base}results/density_calculations/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41a870c8-eed5-4c79-b632-15bedc655d10",
   "metadata": {},
   "source": [
    "# Load estimated non-scaled densities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f93fb8d-12fa-4449-a6ff-867918e40c6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of memberships at all levels: 3489\n",
      "number of memberships at substructure level: 737\n",
      "CPU times: user 37.7 s, sys: 173 ms, total: 37.8 s\n",
      "Wall time: 37.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "# Get all regional density data\n",
    "folder_path = f\"{root_folder}csv/\"\n",
    "filenames = get_all_filenames(folder_path)\n",
    "csv_filenames = get_csv_filenames(folder_path)\n",
    "prefixes = extract_prefix_from_filenames(csv_filenames)\n",
    "unique_prefixes = sorted(list(set(prefixes)))\n",
    "\n",
    "#Create a dict of df, each containing a cell type's occurence in all regions and its densities in all regions\n",
    "result_dataframes = read_and_concat_csv_files_new(csv_filenames, unique_prefixes, folder_path)\n",
    "combined_result_dataframes = combine_rows_and_calculate_average(result_dataframes)\n",
    "shuffled_combined_dataframes = create_combined_dataframe(combined_result_dataframes)\n",
    "\n",
    "file = '/gpfs/bbp.cscs.ch/data/project/proj84/csaba/aibs_10x_mouse_wholebrain/metadata/parcellation_to_parcellation_term_membership_extend.csv'\n",
    "parcellation_annotation = pd.read_csv(file)\n",
    "print(\"number of memberships at all levels:\",len(parcellation_annotation))\n",
    "parcellation_annotation = parcellation_annotation[parcellation_annotation['parcellation_term_set_name'] == 'substructure'] \n",
    "print(\"number of memberships at substructure level:\",len(parcellation_annotation))\n",
    "volumes = parcellation_annotation[['parcellation_label', 'parcellation_index', 'parcellation_term_acronym', 'parcellation_term_set_name', 'parcellation_term_name', 'voxel_count', 'volume_mm3', 'label_numbers', 'cluster_as_filename']]\n",
    "substructure_vol = volumes[volumes['parcellation_term_set_name'] == 'substructure']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "615a7768-212f-4454-a697-ef705f11900f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No issues found in combined_result_dataframes DataFrames.\n"
     ]
    }
   ],
   "source": [
    "# Initialize a list to store keys with problematic values\n",
    "keys_with_issues = []\n",
    "\n",
    "# Iterate over the dictionary\n",
    "for key, df in combined_result_dataframes.items():\n",
    "    # Check for NaN values\n",
    "    has_nan = df.isna().values.any()\n",
    "    \n",
    "    # Check for inf values\n",
    "    has_inf = df.isin([np.inf, -np.inf]).values.any()\n",
    "    \n",
    "    # Check for negative values\n",
    "    has_negative = (df < 0).values.any()\n",
    "    \n",
    "    # If any issues are found, append the key to the list\n",
    "    if has_nan or has_inf or has_negative:\n",
    "        keys_with_issues.append({\n",
    "            \"key\": key,\n",
    "            \"has_nan\": has_nan,\n",
    "            \"has_inf\": has_inf,\n",
    "            \"has_negative\": has_negative\n",
    "        })\n",
    "\n",
    "# Display the keys that contain issues\n",
    "if keys_with_issues:\n",
    "    print(\"The following DataFrames have issues:\")\n",
    "    for issue in keys_with_issues:\n",
    "        print(f\"Key: {issue['key']}, NaN: {issue['has_nan']}, Inf: {issue['has_inf']}, Negative: {issue['has_negative']}\")\n",
    "else:\n",
    "    print(\"No issues found in combined_result_dataframes DataFrames.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4cb3488a-f1a7-48e7-8705-ab48a00fee62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pickle file saved here: /gpfs/bbp.cscs.ch/data/project/proj84/csaba/aibs_10x_mouse_wholebrain/results/density_calculations/\n"
     ]
    }
   ],
   "source": [
    "#write PICKLE file with densities\n",
    "# root_folder = '/gpfs/bbp.cscs.ch/data/project/proj84/csaba/aibs_10x_mouse_wholebrain/results/density_calculations/'\n",
    "# Assuming 'combined_result_dataframes' is your dictionary of DataFrames\n",
    "with open(f'{root_folder}non_scaled_densities_new.pickle', 'wb') as f:\n",
    "    pickle.dump(combined_result_dataframes, f)\n",
    "\n",
    "print(f\"Pickle file saved here: {root_folder}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "27bc7bc1-9e5a-4c7a-b239-ef5f91138fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read CCFv3 annotation volumes (choose 1) for calculating total cell counts\n",
    "# data_folder = \"/gpfs/bbp.cscs.ch/project/proj84/piluso/share/general/warped_augmented_CCFv3/\"\n",
    "# CCFv3, _ = nrrd.read(f'{data_folder}annotation_25_2022_CCFv3.nrrd')\n",
    "# data_folder = \"/gpfs/bbp.cscs.ch/data/project/proj62/csaba/atlas/bbp_prod_files/2022/\"\n",
    "# CCFv3, _ = nrrd.read(f'{data_folder}annotation_25.nrrd')\n",
    "data_folder = \"/gpfs/bbp.cscs.ch/project/proj84/piluso/share/general/warped_augmented_CCFv3/\"\n",
    "CCFv3, _ = nrrd.read(f'{data_folder}annotation_25_2022_CCFv3a.nrrd')\n",
    "# CCFv3, _ = nrrd.read(\"/gpfs/bbp.cscs.ch/data/project/proj84/atlas_pipeline_runs/2024-05-15T22:44:26+02:00/annotation_ccfv3_l23split_barrelsplit_validated.nrrd\")\n",
    "\n",
    "# Create float copy of the annotation voluem, update values in CCFv3 based on conditions\n",
    "#CCFv3_copy = np.copy(CCFv3).astype('float64')\n",
    "\n",
    "#hierarchy_json = '/gpfs/bbp.cscs.ch/home/veraszto/bbp_prod_files/1.json'\n",
    "hierarchy_json = '/gpfs/bbp.cscs.ch/data/project/proj84/atlas_pipeline_runs/2024-05-15T22:44:26+02:00/hierarchy_ccfv3_l23split_barrelsplit.json'\n",
    "region_map = RegionMap.load_json(hierarchy_json)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8406c606-9785-44b0-9172-8022af577f02",
   "metadata": {},
   "source": [
    "# Local (area by area) scaling when necessary\n",
    "Scaling parameters are provided by Blue Brain in the next cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "11d531c8-2e89-4c4f-9451-9c82a0b663d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary from the expected data:\n",
    "data = {\n",
    "    \"id\": [391, 399, 407, 415, 431, 438, 446, 454, 471, 486, 495, 504, 718, 733, 1020],\n",
    "    \"acronym\": [\n",
    "        \"CA1slm\", \"CA1so\", \"CA1sp\", \"CA1sr\", \"CA2slm\", \"CA2so\", \n",
    "        \"CA2sp\", \"CA2sr\", \"CA3slm\", \"CA3so\", \"CA3sp\", \"CA3sr\", \"VPL\", \"VPM\", \"PO\"\n",
    "    ],\n",
    "    \"Region\": [\n",
    "        \"Field CA1, stratum lacunosum-moleculare\", \"Field CA1, stratum oriens\",\n",
    "        \"Field CA1, stratum pyramidale\", \"Field CA1, stratum radiatum\",\n",
    "        \"Field CA2, stratum lacunosum-moleculare\", \"Field CA2, stratum oriens\",\n",
    "        \"Field CA2, stratum pyramidale\", \"Field CA2, stratum radiatum\",\n",
    "        \"Field CA3, stratum lacunosum-moleculare\", \"Field CA3, stratum oriens\",\n",
    "        \"Field CA3, stratum pyramidale\", \"Field CA3, stratum radiatum\",\n",
    "        \"Ventral posterolateral nucleus of the thalamus\", \"Ventral posteromedial nucleus of the thalamus\",\n",
    "        \"Posterior complex of the thalamus\"\n",
    "    ],\n",
    "    \"Expected Inhibitory Dorsal\": [\n",
    "        8420, 6480, 13520, 6480, 8420, 6480, 13520, 3240, 5780, 3170, 7560, 7890, \"\", \"\", \"\"\n",
    "    ],\n",
    "    \"Expected Inhibitory Ventral\": [\n",
    "        8820, 10500, 10130, 10500, 8820, 10500, 10130, 4260, 7200, 5460, 10540, 6590, \"\", \"\", \"\"\n",
    "    ],\n",
    "    \"Expected Neurons Dorsal\": [\n",
    "        \"\", \"\", 447500, \"\", \"\", \"\", 447500, \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\"\n",
    "    ],\n",
    "    \"Expected Neurons Ventral\": [\n",
    "        \"\", \"\", 180500, \"\", \"\", \"\", 180500, \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\"\n",
    "    ],\n",
    "    \"exc_mm3\": [\n",
    "        \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", 55340.64, 67940.58, \"\"\n",
    "    ],\n",
    "    \"inh_mm3\": [\n",
    "        8620, 8490, 11825, 8490, 8620, 8490, 11825, 3750, 6490, 4315, 9050, 7240, 2126.28, 2978.61, 161.08663\n",
    "    ],\n",
    "    \"neurons_mm3\": [\n",
    "        \"\", \"\", 314000, \"\", \"\", \"\", 314000, \"\", \"\", \"\", 172400, \"\", 57466.92, 70919.19, \"\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Create a DataFrame from the dictionary\n",
    "df_e = pd.DataFrame(data)\n",
    "\n",
    "\n",
    "# New data to be added\n",
    "new_data = {\n",
    "    \"id\": [212, 220, 228, 236, 244, 477],\n",
    "    \"acronym\": [\n",
    "        \"MOBglomerularlayer\", \"MOBgr\", \"MOBipl\", \"MOBmi\", \"MOBopl\", \"STR\"\n",
    "    ],\n",
    "    \"Region\": [\n",
    "        \"Main olfactory bulb, glomerular layer\", \"Main olfactory bulb, granule layer\",\n",
    "        \"Main olfactory bulb, inner plexiform layer\", \"Main olfactory bulb, mitral layer\",\n",
    "        \"Main olfactory bulb, outer plexiform layer\", \"Striatum\"\n",
    "    ],\n",
    "    \"Expected Inhibitory Dorsal\": [\"\", \"\", \"\", \"\", \"\", \"\"],\n",
    "    \"Expected Inhibitory Ventral\": [\"\", \"\", \"\", \"\", \"\", \"\"],\n",
    "    \"Expected Neurons Dorsal\": [\"\", \"\", \"\", \"\", \"\", \"\"],\n",
    "    \"Expected Neurons Ventral\": [\"\", \"\", \"\", \"\", \"\", \"\"],\n",
    "    \"exc_mm3\": [\"\", \"\", \"\", \"\", \"\", \"\"],\n",
    "    \"inh_mm3\": [\"\", \"\", \"\", \"\", \"\", \"\"],\n",
    "    \"neurons_mm3\": [\n",
    "        630000, 710000, 150000, 350000, 80000, 78560\n",
    "    ]\n",
    "}\n",
    "df_new = pd.DataFrame(new_data)\n",
    "\n",
    "# Concatenate the new data with the existing data\n",
    "df_expected = pd.concat([df_e, df_new], ignore_index=True)\n",
    "df_expected.to_csv('/gpfs/bbp.cscs.ch/data/project/proj84/csaba/aibs_10x_mouse_wholebrain/results/expected_data.csv', index=False)\n",
    "\n",
    "#Add children to the regions which need to change to include non-leaf-region changes:\n",
    "file = '/gpfs/bbp.cscs.ch/data/project/proj84/csaba/aibs_10x_mouse_wholebrain/results/df_hierarchy_ccfv3_l23split_barrelsplit.csv'\n",
    "hierarchy = pd.read_csv(file, index_col=0)\n",
    "\n",
    "# Merge df_expected with hierarchy on 'id' to get the 'children' column\n",
    "df_expected = df_expected.merge(hierarchy[['id', 'children', 'acr_list']], on='id', how='left')\n",
    "\n",
    "import ast\n",
    "df_expected.loc[: , 'children'] = df_expected.loc[: , 'children'].apply(ast.literal_eval)\n",
    "\n",
    "# Add new columns to df_expected\n",
    "df_expected['exc_mm3_ratio'] = np.nan\n",
    "df_expected['inh_mm3_ratio'] = np.nan\n",
    "df_expected['neurons_mm3_ratio'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af38560-b2d0-4b1e-8dce-ccd2924cca5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "180c9426-8bd0-4f50-a7e9-a54588d8b0da",
   "metadata": {},
   "source": [
    "## Total nrrd creation\n",
    "We can separate cell types into larger (hierarchical groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dbba2e2e-1489-4e46-8229-85ccef42797b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 16.2 s, sys: 403 ms, total: 16.6 s\n",
      "Wall time: 16.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "meta_path = \"/gpfs/bbp.cscs.ch/data/project/proj84/csaba/aibs_10x_mouse_wholebrain/metadata/WMB-10X/20231215/views/cell_metadata_with_cluster_annotation.csv\"\n",
    "columns_to_read = ['class', 'subclass', 'cluster']\n",
    "#metadata = pd.read_csv(meta_path, dtype={'cell_label':str}, low_memory=False)\n",
    "metadata = pd.read_csv(meta_path, usecols=columns_to_read, )\n",
    "\n",
    "n_classes = ['01 IT-ET Glut', '02 NP-CT-L6b Glut', '03 OB-CR Glut',\n",
    "       '04 DG-IMN Glut', '05 OB-IMN GABA', '06 CTX-CGE GABA',\n",
    "       '07 CTX-MGE GABA', '08 CNU-MGE GABA', '09 CNU-LGE GABA',\n",
    "       '10 LSX GABA', '11 CNU-HYa GABA', '12 HY GABA', '13 CNU-HYa Glut',\n",
    "       '14 HY Glut', '15 HY Gnrh1 Glut', '16 HY MM Glut', '17 MH-LH Glut',\n",
    "       '18 TH Glut', '19 MB Glut', '20 MB GABA', '21 MB Dopa',\n",
    "       '22 MB-HB Sero', '23 P Glut', '24 MY Glut', '25 Pineal Glut',\n",
    "       '26 P GABA', '27 MY GABA', '28 CB GABA', '29 CB Glut',]\n",
    "\n",
    "nn_classes = ['30 Astro-Epen', '31 OPC-Oligo', '32 OEC', '33 Vascular',\n",
    "       '34 Immune']\n",
    "\n",
    "exc = ['01 IT-ET Glut', '02 NP-CT-L6b Glut', '03 OB-CR Glut',\n",
    "      '04 DG-IMN Glut', '13 CNU-HYa Glut', '14 HY Glut', '15 HY Gnrh1 Glut', '16 HY MM Glut', '17 MH-LH Glut',\n",
    "      '18 TH Glut', '19 MB Glut', '23 P Glut', '24 MY Glut', '25 Pineal Glut', '29 CB Glut',]\n",
    "inh = ['05 OB-IMN GABA', '06 CTX-CGE GABA', '07 CTX-MGE GABA', '08 CNU-MGE GABA', '09 CNU-LGE GABA',\n",
    "      '10 LSX GABA', '11 CNU-HYa GABA', '12 HY GABA', '20 MB GABA', '26 P GABA', '27 MY GABA', '28 CB GABA', ]\n",
    "other = ['21 MB Dopa', '22 MB-HB Sero', ]\n",
    "exci_inhib_sum = exc + inh\n",
    "\n",
    "astrotypes = ['5206 Bergmann NN_1', '5207 Astro-CB NN_1', '5208 Astro-NT NN_1',\n",
    "       '5209 Astro-NT NN_1', '5210 Astro-NT NN_1', '5211 Astro-NT NN_1',\n",
    "       '5212 Astro-NT NN_1', '5213 Astro-NT NN_1', '5214 Astro-NT NN_2',\n",
    "       '5215 Astro-NT NN_2', '5216 Astro-NT NN_2', '5217 Astro-NT NN_2',\n",
    "       '5218 Astro-TE NN_1', '5219 Astro-TE NN_1', '5220 Astro-TE NN_1',\n",
    "       '5221 Astro-TE NN_1', '5222 Astro-TE NN_2', '5223 Astro-TE NN_2',\n",
    "       '5224 Astro-TE NN_3', '5225 Astro-TE NN_3', '5226 Astro-TE NN_3',\n",
    "       '5227 Astro-TE NN_3', '5228 Astro-TE NN_4', '5229 Astro-TE NN_5',\n",
    "       '5230 Astro-TE NN_5', '5231 Astro-OLF NN_1', '5232 Astro-OLF NN_1',\n",
    "       '5233 Astro-OLF NN_2', '5234 Astro-OLF NN_2',\n",
    "       '5235 Astro-OLF NN_3', '5236 Astro-OLF NN_3',]\n",
    "\n",
    "microglia = ['5312 Microglia NN_1']\n",
    "\n",
    "oligos = [ '5266 OPC NN_1', '5267 OPC NN_1',\n",
    "       '5268 OPC NN_1', '5269 OPC NN_1', '5270 OPC NN_1', '5271 OPC NN_2',\n",
    "       '5272 COP NN_1', '5273 COP NN_1', '5274 COP NN_1', '5275 COP NN_1',\n",
    "       '5276 COP NN_1', '5277 COP NN_1', '5278 NFOL NN_2',\n",
    "       '5279 NFOL NN_2', '5280 NFOL NN_2', '5281 NFOL NN_2',\n",
    "       '5282 MFOL NN_3', '5283 MFOL NN_3', '5284 MOL NN_4',\n",
    "       '5285 MOL NN_4', '5286 MOL NN_4', '5287 MOL NN_4', '5288 MOL NN_4',]\n",
    "\n",
    "glia = astrotypes + microglia + oligos\n",
    "\n",
    "neurontypes = np.unique(metadata[metadata['class'].isin(n_classes)]['cluster'].values)\n",
    "nonneurontypes = np.unique(metadata[metadata['class'].isin(nn_classes)]['cluster'].values)\n",
    "exctypes = np.unique(metadata[metadata['class'].isin(exc)]['cluster'].values)\n",
    "inhtypes = np.unique(metadata[metadata['class'].isin(inh)]['cluster'].values)\n",
    "othertypes = np.unique(metadata[metadata['class'].isin(other)]['cluster'].values)\n",
    "exci_inhib_sum = np.unique(metadata[metadata['class'].isin(exci_inhib_sum)]['cluster'].values)\n",
    "celltypes = np.unique(metadata['cluster'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4265aea7-d183-4645-8686-75b5a4e95778",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Helper function to create total cell count values for a 3D brain\n",
    "\n",
    "# import re\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "\n",
    "def nrrd_for_validation(df, parcellation_annotation, CCFv3):\n",
    "    all_ids_for_df = []\n",
    "    df_comb = pd.DataFrame()\n",
    "\n",
    "    for regionname in df.index.values[0:]:\n",
    "        density = df.loc[regionname, 'density_mm3']\n",
    "        #annotation_id_info = substructures[substructures['cluster_as_filename'] == regionname]\n",
    "        annotation_id_info = parcellation_annotation[parcellation_annotation['cluster_as_filename'] == regionname]\n",
    "\n",
    "        Annotation2020ids = [int(re.search(r'\\d+$', s).group()) for s in annotation_id_info['parcellation_label'].values]\n",
    "        df_sub = pd.DataFrame({'density': density}, index=Annotation2020ids)\n",
    "        df_comb = pd.concat([df_comb, df_sub])\n",
    "        all_ids_for_df.append(Annotation2020ids)\n",
    "\n",
    "    all_ids_for_df = [value for sublist in all_ids_for_df for value in sublist]\n",
    "    all_ids_for_df.append(0)\n",
    "    #Place to put extra regions not part of Allen's Parcellation annotation\n",
    "\n",
    "    outside = 0\n",
    "    outsideid = [0]\n",
    "    df_sub = pd.DataFrame({'density': outside}, index=outsideid)\n",
    "    df_comb = pd.concat([df_comb, df_sub])\n",
    "\n",
    "    CCFv3_copy = CCFv3.copy()\n",
    "\n",
    "    # Expression is 0 in those regions where we don't have any info:\n",
    "    CCFv3_copy[~np.isin(CCFv3_copy, all_ids_for_df)] = 0.0 \n",
    "\n",
    "    # Expression is non-zero in these leaf region(s)\n",
    "    for index, row in df_comb.iterrows():\n",
    "        density_value = row['density']\n",
    "        region_id = index\n",
    "        CCFv3_copy[np.isin(CCFv3, region_id)] = density_value\n",
    "\n",
    "    #Create outside of the brain as 0\n",
    "    CCFv3_copy[np.isin(CCFv3, int(0))] = 0\n",
    "\n",
    "    return CCFv3_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "64114e5d-4fbe-4fc5-9f16-02aa92d38898",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/gpfs/bbp.cscs.ch/data/project/proj84/csaba/aibs_10x_mouse_wholebrain/results/density_calculations/non_scaled_total_neuron_densities.nrrd\n",
      "/gpfs/bbp.cscs.ch/data/project/proj84/csaba/aibs_10x_mouse_wholebrain/results/density_calculations/non_scaled_total_excitatory_densities.nrrd\n",
      "/gpfs/bbp.cscs.ch/data/project/proj84/csaba/aibs_10x_mouse_wholebrain/results/density_calculations/non_scaled_total_inhibitory_densities.nrrd\n",
      "/gpfs/bbp.cscs.ch/data/project/proj84/csaba/aibs_10x_mouse_wholebrain/results/density_calculations/non_scaled_total_astrotypes_densities.nrrd\n",
      "/gpfs/bbp.cscs.ch/data/project/proj84/csaba/aibs_10x_mouse_wholebrain/results/density_calculations/non_scaled_total_microglia_densities.nrrd\n",
      "/gpfs/bbp.cscs.ch/data/project/proj84/csaba/aibs_10x_mouse_wholebrain/results/density_calculations/non_scaled_total_oligocyte_densities.nrrd\n",
      "/gpfs/bbp.cscs.ch/data/project/proj84/csaba/aibs_10x_mouse_wholebrain/results/density_calculations/non_scaled_total_glia_densities.nrrd\n",
      "/gpfs/bbp.cscs.ch/data/project/proj84/csaba/aibs_10x_mouse_wholebrain/results/density_calculations/non_scaled_total_excinh_densities.nrrd\n",
      "/gpfs/bbp.cscs.ch/data/project/proj84/csaba/aibs_10x_mouse_wholebrain/results/density_calculations/non_scaled_total_celltypes_densities.nrrd\n",
      "/gpfs/bbp.cscs.ch/data/project/proj84/csaba/aibs_10x_mouse_wholebrain/results/density_calculations/non_scaled_total_nonneuron_densities.nrrd\n",
      "CPU times: user 1min 6s, sys: 5.32 s, total: 1min 11s\n",
      "Wall time: 10min 10s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#from multiprocessing import Pool\n",
    "\n",
    "def process_type(types, file_name):\n",
    "    # Filter DataFrames based on types\n",
    "    filtered_dataframes = {key: value for key, value in shuffled_combined_dataframes.items() if key in types}\n",
    "    \n",
    "    # Combine filtered DataFrames\n",
    "    combined_df = pd.concat(filtered_dataframes.values())\n",
    "    \n",
    "    # Sum the combined DataFrame by index\n",
    "    summed_df = combined_df.groupby(combined_df.index).sum()\n",
    "    \n",
    "    # Validate result\n",
    "    result = nrrd_for_validation(summed_df, parcellation_annotation, CCFv3)\n",
    "    \n",
    "    # Clean up\n",
    "    del combined_df, summed_df, filtered_dataframes\n",
    "\n",
    "    return (result, file_name)\n",
    "\n",
    "def main():\n",
    "    # Define the parameters for each process\n",
    "    tasks = [\n",
    "        (neurontypes, \"non_scaled_total_neuron_densities\"),\n",
    "        (exctypes, \"non_scaled_total_excitatory_densities\"),\n",
    "        (inhtypes, \"non_scaled_total_inhibitory_densities\"),\n",
    "        (astrotypes, \"non_scaled_total_astrotypes_densities\"),\n",
    "        (microglia, \"non_scaled_total_microglia_densities\"),\n",
    "        (oligos, \"non_scaled_total_oligocyte_densities\"),\n",
    "        (glia, \"non_scaled_total_glia_densities\"),\n",
    "        (exci_inhib_sum, \"non_scaled_total_excinh_densities\"),\n",
    "        (celltypes, \"non_scaled_total_celltypes_densities\"),\n",
    "        (nonneurontypes, \"non_scaled_total_nonneuron_densities\")\n",
    "    ]\n",
    "    \n",
    "    # Create a multiprocessing Pool\n",
    "    with mp.Pool(processes=mp.cpu_count()) as pool:\n",
    "        results = pool.starmap(process_type, tasks)\n",
    "    \n",
    "    # Sequentially write the .nrrd files to avoid concurrent writes\n",
    "    for result, file_name in results:\n",
    "        nrrd.write(f\"{root_folder}{file_name}.nrrd\", result)\n",
    "        print(f\"{root_folder}{file_name}.nrrd\")\n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "97208254-2ea2-4f1b-a307-38c5a37c89da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "non_scaled_total_neuron_densities.nrrd  was opened.\n",
      "non_scaled_total_excitatory_densities.nrrd  was opened.\n",
      "non_scaled_total_inhibitory_densities.nrrd  was opened.\n"
     ]
    }
   ],
   "source": [
    "#Add scaling parameter to df_expected too by loading scaled total density files and search for corresponding values (computed earlier)\n",
    "\n",
    "#NEURON\n",
    "filename = \"non_scaled_total_neuron_densities.nrrd\"\n",
    "full_path = os.path.join(root_folder, filename)\n",
    "if os.path.isfile(full_path):\n",
    "    neuron_total, _ = nrrd.read(full_path)\n",
    "    print(filename, \" was opened.\")\n",
    "\n",
    "#EXC\n",
    "filename = \"non_scaled_total_excitatory_densities.nrrd\"\n",
    "full_path = os.path.join(root_folder, filename)\n",
    "if os.path.isfile(full_path):\n",
    "    exc_total, _ = nrrd.read(full_path)\n",
    "    print(filename, \" was opened.\")\n",
    "    \n",
    "#INH        \n",
    "filename = \"non_scaled_total_inhibitory_densities.nrrd\"\n",
    "full_path = os.path.join(root_folder, filename)\n",
    "if os.path.isfile(full_path):\n",
    "    inh_total, _ = nrrd.read(full_path)\n",
    "    print(filename, \" was opened.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b7e2587b-b0d0-41dd-80d3-59135a10ef2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 58.9 ms, sys: 1.03 s, total: 1.09 s\n",
      "Wall time: 5.38 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "'''We divide by: mean expected / transcriptomic mean densities..'''\n",
    "\n",
    "# Arrays to process\n",
    "arrays = {\n",
    "    'neurons_mm3': neuron_total,\n",
    "    'inh_mm3': inh_total,\n",
    "    'exc_mm3': exc_total,\n",
    "}\n",
    "\n",
    "# Worker function to process each row\n",
    "def process_row(row):\n",
    "    id_ = row['id'] \n",
    "    acr = row['acronym']\n",
    "    name = row['Region']\n",
    "    ids = row['children']\n",
    "    ids.append(id_) #Make sure you add the original id_ to the children\n",
    "    \n",
    "    \n",
    "    # Create a mask for the current id list\n",
    "    mask = np.isin(CCFv3, [ids])\n",
    "    \n",
    "    # Calculate mean/median values (can place NaN or None in the regions not present in CCfV3)\n",
    "    # mean_values = {name: arr[mask].mean() if arr[mask].size > \n",
    "    #                0 else np.nan for name, arr in arrays.items()}\n",
    "    mean_values = {name: arr[mask].mean() if arr[mask].size > \n",
    "                   0 else None for name, arr in arrays.items()}\n",
    "    # mean_values = {name: np.median(arr[mask]) if arr[mask].size > \n",
    "    #                0 else None for name, arr in arrays.items()}\n",
    "\n",
    "    # Update row with ratio values\n",
    "    if mean_values['exc_mm3'] is not np.nan and isinstance(row['exc_mm3'], (int, float)):\n",
    "        row['exc_mm3_ratio'] = row['exc_mm3'] / mean_values['exc_mm3']\n",
    "    if mean_values['inh_mm3'] is not np.nan and isinstance(row['inh_mm3'], (int, float)):\n",
    "        row['inh_mm3_ratio'] = row['inh_mm3'] / mean_values['inh_mm3']\n",
    "    if mean_values['neurons_mm3'] is not np.nan and isinstance(row['neurons_mm3'], (int, float)):\n",
    "        row['neurons_mm3_ratio'] = row['neurons_mm3'] / mean_values['neurons_mm3']\n",
    "    \n",
    "    return row\n",
    "    \n",
    "    \n",
    "# Use multiprocessing Pool to process rows in parallel\n",
    "if __name__ == '__main__':\n",
    "    with mp.Pool(processes=mp.cpu_count()) as pool:\n",
    "        new_data = pool.map(process_row, [row for _, row in df_expected.iterrows()])\n",
    "    \n",
    "    # Convert the list of rows back to a DataFrame\n",
    "    df_expected = pd.DataFrame(new_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "49a39061-9714-4d3f-9c50-8bc37e7463ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STR  is not a leaf region recognised by transcriptomics data, it will be split to its leaves\n",
      "30 21 51\n"
     ]
    }
   ],
   "source": [
    "#import ast \n",
    "#Note that we will scale the scaled data: scaled_combined_result_dataframes\n",
    "combined_result_dataframes_copy = copy.deepcopy(combined_result_dataframes)\n",
    "\n",
    "\n",
    "for reg in df_expected['acronym'].values:\n",
    "    concatenated_result = np.array(df_expected['acronym'].values) \n",
    "    if reg not in list(combined_result_dataframes_copy.keys()):\n",
    "        print(reg, \" is not a leaf region recognised by transcriptomics data, it will be split to its leaves\")\n",
    "        #leaves_list = df_expected[df_expected['acronym'] == reg]['children'].iat[0]\n",
    "        acr_list_str = df_expected[df_expected['acronym'] == reg]['acr_list'].iat[0]\n",
    "        acr_list = ast.literal_eval(acr_list_str)\n",
    "\n",
    "        # Concatenate the array and the list to cover the full area where secondary scaling takes effect\n",
    "        # We combine the leaf regions with the list of regions non leaf regions\n",
    "        concatenated_result = np.concatenate((concatenated_result, acr_list))\n",
    "        print(len(acr_list), len(df_expected['acronym'].values), len(concatenated_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "61494096-9a6e-48bb-a03e-77846540a6a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Total number of transplants\n",
    "len(concatenated_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "acb7b16d-2aff-4393-9dcf-1621d1cc8785",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>acronym</th>\n",
       "      <th>Region</th>\n",
       "      <th>Expected Inhibitory Dorsal</th>\n",
       "      <th>Expected Inhibitory Ventral</th>\n",
       "      <th>Expected Neurons Dorsal</th>\n",
       "      <th>Expected Neurons Ventral</th>\n",
       "      <th>exc_mm3</th>\n",
       "      <th>inh_mm3</th>\n",
       "      <th>neurons_mm3</th>\n",
       "      <th>children</th>\n",
       "      <th>acr_list</th>\n",
       "      <th>exc_mm3_ratio</th>\n",
       "      <th>inh_mm3_ratio</th>\n",
       "      <th>neurons_mm3_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>244</td>\n",
       "      <td>MOBopl</td>\n",
       "      <td>Main olfactory bulb, outer plexiform layer</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>80000</td>\n",
       "      <td>[244, 244]</td>\n",
       "      <td>['MOBopl']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.399253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>477</td>\n",
       "      <td>STR</td>\n",
       "      <td>Striatum</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>78560</td>\n",
       "      <td>[3034756217, 672, 56, 998, 549009199, 310, 333...</td>\n",
       "      <td>['STR_O', 'CP', 'ACB', 'FS', 'LSS', 'SF', 'SH'...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.496897</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id acronym                                      Region  \\\n",
       "19  244  MOBopl  Main olfactory bulb, outer plexiform layer   \n",
       "20  477     STR                                    Striatum   \n",
       "\n",
       "   Expected Inhibitory Dorsal Expected Inhibitory Ventral  \\\n",
       "19                                                          \n",
       "20                                                          \n",
       "\n",
       "   Expected Neurons Dorsal Expected Neurons Ventral exc_mm3 inh_mm3  \\\n",
       "19                                                                    \n",
       "20                                                                    \n",
       "\n",
       "   neurons_mm3                                           children  \\\n",
       "19       80000                                         [244, 244]   \n",
       "20       78560  [3034756217, 672, 56, 998, 549009199, 310, 333...   \n",
       "\n",
       "                                             acr_list  exc_mm3_ratio  \\\n",
       "19                                         ['MOBopl']            NaN   \n",
       "20  ['STR_O', 'CP', 'ACB', 'FS', 'LSS', 'SF', 'SH'...            NaN   \n",
       "\n",
       "    inh_mm3_ratio  neurons_mm3_ratio  \n",
       "19            NaN           0.399253  \n",
       "20            NaN           0.496897  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_expected.tail(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0aad49d4-06c9-4b83-907e-a9fdc55b9c34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AAA, ACB, BA, CA1slm, CA1so, CA1sp, CA1sr, CA2slm, CA2so, CA2sp, CA2sr, CA3slm, CA3so, CA3sp, CA3sr, CEAc, CEAl, CEAm, CP, FS, IA, LSc, LSr, LSv, MOBglomerularlayer, MOBgr, MOBipl, MOBmi, MOBopl, PO, SF, SH, VPL, VPM is a leaf region which will be transplanted.\n",
      "CPU times: user 92.7 ms, sys: 4.93 ms, total: 97.6 ms\n",
      "Wall time: 96.3 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# del scaled_combined_result_dataframes\n",
    "# We create the dict of dfs anew!\n",
    "scaled_combined_result_dataframes = {}\n",
    "keys_to_print = []\n",
    "\n",
    "#Do the 2ndary scaling: we check every transcriptomic region and scale their cell types if needed: \n",
    "for key, df in combined_result_dataframes_copy.items():\n",
    "    if key in concatenated_result:\n",
    "        keys_to_print.append(key)\n",
    "        # We find the row where this region is listed (can be a substring if the row is not a leaf region)\n",
    "        matches = df_expected.map(lambda x: key in str(x))\n",
    "        rows_with_substring = df_expected[matches.any(axis=1)]\n",
    "        # If the region has a non-NAN value in the ratios, we multiply that type of cells with the ratio\n",
    "        if not rows_with_substring.empty and pd.notna(rows_with_substring['exc_mm3_ratio'].iloc[0]):\n",
    "            mask = df.index.isin(exctypes)\n",
    "            df.loc[mask, 'density_mm3'] *= rows_with_substring['exc_mm3_ratio'].iloc[0]\n",
    "            scaled_combined_result_dataframes[key] = df\n",
    "        #break\n",
    "        if not rows_with_substring.empty and pd.notna(rows_with_substring['inh_mm3_ratio'].iloc[0]):\n",
    "            mask = df.index.isin(inhtypes)\n",
    "            df.loc[mask, 'density_mm3'] *= rows_with_substring['inh_mm3_ratio'].iloc[0]\n",
    "            scaled_combined_result_dataframes[key] = df\n",
    "\n",
    "        if not rows_with_substring.empty and pd.notna(rows_with_substring['neurons_mm3_ratio'].iloc[0]):\n",
    "            mask = df.index.isin(neurontypes)\n",
    "            df.loc[mask, 'density_mm3'] *= rows_with_substring['neurons_mm3_ratio'].iloc[0]\n",
    "            scaled_combined_result_dataframes[key] = df\n",
    "            #break\n",
    "        #print(\"Deleting data for \" + key)\n",
    "        del key, df        \n",
    "    else:\n",
    "       #In this case we don't have to scale\n",
    "        scaled_combined_result_dataframes[key] = df\n",
    "        del key, df\n",
    "\n",
    "if keys_to_print:\n",
    "    print(\", \".join(keys_to_print) + \" is a leaf region which will be transplanted.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "28c20fe5-13c9-4b48-928c-bf7876e77e99",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved here: /gpfs/bbp.cscs.ch/data/project/proj84/csaba/aibs_10x_mouse_wholebrain/results/density_calculations/\n"
     ]
    }
   ],
   "source": [
    "# Assuming 'scaled_combined_result_dataframes' is your dictionary of DataFrames\n",
    "with open(f'{root_folder}scaled_densities_local.pickle', 'wb') as f:\n",
    "    pickle.dump(scaled_combined_result_dataframes, f)\n",
    "\n",
    "print(f\"Saved here: {root_folder}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1fd7c96a-7c5f-4886-8117-00dacffd32a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#del scaled_combined_result_dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca21ee6c-495a-44d8-8fbd-112c14ea60f4",
   "metadata": {},
   "source": [
    "# Global scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc9f368-25f4-4281-a5f9-644c88d444b7",
   "metadata": {},
   "source": [
    "This notebook starts after data was created from MERFISH slices and stored as csv and pickle files. We examine scaling individual cell groups based on literature: https://www.pnas.org/doi/full/10.1073/pnas.0604911103\n",
    "\n",
    "Total cells (M): 108.69 ± 16.25\n",
    "\n",
    "Total neurons (M): 70.89 ± 10.41\n",
    "\n",
    "CCTX: 17.8 ± 3.4% of neurons (this is not the isocortex)\n",
    "\n",
    "CRB: 59.0 ± 5.0% of neurons\n",
    "\n",
    "\"Cerebral cortex\" 688 = \"Cortical plate\" 695 + \"Cortical subplate\" 703\n",
    "\"Cerebral nuclei is not part of the cer.ctx)\n",
    "Cerebral cortex is not the Cerebellar cortex (the Cerebellar cortex is part of the Cerebellum)\n",
    "From test_tutorial_cerebellum.ipynb we decided to only scale exc cells (ie granular layer) in the CRB.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b4bf06f2-218f-48f7-ba77-b20261824750",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pickle file.\n"
     ]
    }
   ],
   "source": [
    "#If we want we can load the previous step\n",
    "\n",
    "file = os.path.join( root_folder, 'scaled_densities_local.pickle' )\n",
    "#file = os.path.join( root_folder, 'non_scaled_densities_new.pickle' )\n",
    "\n",
    "#Load region id volumes from volume_calc_from_template.ipynb\n",
    "with open(file, 'rb') as pickle_file:\n",
    "    scaled_combined_result_dataframes = pickle.load(pickle_file)\n",
    "print(\"Loaded pickle file.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9b096194-d149-494f-aeaa-88c0bf3b4ead",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neurons only: \n",
      "CTX: 12,618,420 CRB: 41,825,100 REST: 16,446,480\n"
     ]
    }
   ],
   "source": [
    "#in this cell we just give ground truth cell counts from the paper\n",
    "total_cells = 108.69 * 1_000_000\n",
    "total_neurons = 70.89 * 1_000_000\n",
    "total_ctx = total_neurons * 17.8 / 100 #17.8% of the total neurons\n",
    "total_crb = total_neurons * 59.0 / 100 #59% of the total neurons\n",
    "total_rest = total_neurons * ( 100 - 59.0 -17.8 )/ 100\n",
    "print(\"Neurons only: \")\n",
    "print(\"CTX: \" '{:,.0f}'.format(total_ctx,), \"CRB: \" '{:,.0f}'.format(total_crb),\"REST: \" '{:,.0f}'.format(total_rest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4f9bcfea-11b5-4479-97d7-e15560ac3706",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Volume of the voxel in mm^3: 1.5625e-05\n",
      "Volume of the voxel in mm^3: 1e-06\n"
     ]
    }
   ],
   "source": [
    "#Next we have to convert densities to cell counts for the scaling. This way we can measure the scaling ratio between the current densities and the desired ones. For this we need voxel size\n",
    "\n",
    "# Edge length of the voxel in millimeters\n",
    "edge_length_mm = 25.0 / 1000.0  # Convert micrometers to millimeters\n",
    "\n",
    "# Calculate the volume of the voxel in cubic millimeters\n",
    "volume25_mm3 = round(edge_length_mm ** 3, 10)\n",
    "\n",
    "print(\"Volume of the voxel in mm^3:\", volume25_mm3)\n",
    "\n",
    "# Edge length of the voxel in millimeters\n",
    "edge_length_mm = 10.0 / 1000.0  # Convert micrometers to millimeters\n",
    "\n",
    "# Calculate the volume of the voxel in cubic millimeters\n",
    "volume10_mm3 = round(edge_length_mm ** 3, 10)\n",
    "\n",
    "print(\"Volume of the voxel in mm^3:\", volume10_mm3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88dfd795-794d-42d3-89a4-f77a7e251632",
   "metadata": {},
   "source": [
    "Next, we convert densities to total cell number / region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e4314351-d7b9-44bd-a4cc-e805134d4674",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "annotation vol is 25 um resolution but it is larger than the Allen Institute's CCFv3\n",
      "Saved here: /gpfs/bbp.cscs.ch/data/project/proj84/csaba/aibs_10x_mouse_wholebrain/results/density_calculations/\n",
      "CPU times: user 40.4 s, sys: 11.3 ms, total: 40.4 s\n",
      "Wall time: 40.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "scaled_total_cells_local = {}\n",
    "\n",
    "if CCFv3.shape == (528, 320, 456):\n",
    "    print(\"annotation vol is 25 um resolution\")\n",
    "    for region_name, df in scaled_combined_result_dataframes.items():\n",
    "        # Get the corresponding volume for the region\n",
    "        label = volumes.loc[volumes['cluster_as_filename'] == region_name, 'parcellation_label'].values[0]\n",
    "        id_ = int(label.rsplit('-', 1)[-1])\n",
    "        #id_ = region_map.find(region_name, attr='name', ignore_case=True, with_descendants=False)\n",
    "        volume = np.count_nonzero(CCFv3 == id_) * volume25_mm3\n",
    "        #print(region_name, label, id_, f\"{volume:.6f}\")\n",
    "        # Calculate total cells by multiplying density by volume\n",
    "        scaled_total_cells_local[region_name] = pd.DataFrame({'total_cellnumber': df['density_mm3'] * volume})\n",
    "\n",
    "elif CCFv3.shape == (566, 320, 456):\n",
    "    print(\"annotation vol is 25 um resolution but it is larger than the Allen Institute's CCFv3\")\n",
    "    for region_name, df in scaled_combined_result_dataframes.items():\n",
    "        # Get the corresponding volume for the region\n",
    "        label = volumes.loc[volumes['cluster_as_filename'] == region_name, 'parcellation_label'].values[0]\n",
    "        id_ = int(label.rsplit('-', 1)[-1])\n",
    "        #id_ = region_map.find(region_name, attr='name', ignore_case=True, with_descendants=False)\n",
    "        volume = np.count_nonzero(CCFv3 == id_) * volume25_mm3\n",
    "        #print(region_name, label, id_, f\"{volume:.6f}\")\n",
    "        # Calculate total cells by multiplying density by volume\n",
    "        scaled_total_cells_local[region_name] = pd.DataFrame({'total_cellnumber': df['density_mm3'] * volume})\n",
    "\n",
    "elif CCFv3.shape == (1320, 800, 1140) or CCFv3.shape == (1140, 800, 1320):\n",
    "    print(\"*** annotation vol is 10 um resolution *** \")\n",
    "    for region_name, df in scaled_combined_result_dataframes.items():\n",
    "        # Get the corresponding volume for the region\n",
    "        label = volumes.loc[volumes['cluster_as_filename'] == region_name, 'parcellation_label'].values[0]\n",
    "        id_ = int(label.rsplit('-', 1)[-1])\n",
    "        #id_ = region_map.find(region_name, attr='name', ignore_case=True, with_descendants=False)\n",
    "        #print(region_name, label, id_)\n",
    "        \n",
    "        if CCFv3.shape == (1320, 800, 1140):\n",
    "            volume = np.count_nonzero(CCFv3 == id_) * volume10_mm3\n",
    "        elif CCFv3.shape == (1140, 800, 1320):\n",
    "            volume = np.count_nonzero(CCFv3 == id_) * volume10_mm3 \n",
    "        # Calculate total cells by multiplying density by volume\n",
    "        print(region_name, label, id_, f\"{volume:.6f}\")\n",
    "        scaled_total_cells_local[region_name] = pd.DataFrame({'total_cellnumber': df['density_mm3'] * volume})\n",
    "else:\n",
    "    print(\"*** Annotation volume shape is not understood. *** \")\n",
    "\n",
    "#We can save the file just in case. \n",
    "\n",
    "# Assuming 'scaled_total_cells_local' is your dictionary of DataFrames\n",
    "with open(f'{root_folder}scaled_total_cells_local.pickle', 'wb') as f:\n",
    "    pickle.dump(scaled_total_cells_local, f)\n",
    "\n",
    "# # Assuming you skipped transplantation and only want to run global scaling \n",
    "# with open(f'{root_folder}scaled_globalonly_cells.pickle', 'wb') as f:\n",
    "#     pickle.dump(scaled_total_cells_local, f)\n",
    "\n",
    "print(f\"Saved here: {root_folder}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e9c93af0-cfb1-43c0-adf0-cd6acae9cf9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now, we need to isolate specific regions from the others to scale them differently\n",
    "\n",
    "isocortex = (\n",
    "    region_map.find(\"Isocortex\", attr=\"name\", with_descendants=True)\n",
    "    | region_map.find(\"Entorhinal area\", attr=\"name\", with_descendants=True)\n",
    "    | region_map.find(\"Piriform area\", attr=\"name\", with_descendants=True)\n",
    ")\n",
    "cerebellum = region_map.find(\n",
    "        \"Cerebellum\", attr=\"name\", with_descendants=True\n",
    "    ) | region_map.find(\"arbor vitae\", attr=\"name\", with_descendants=True)\n",
    "\n",
    "fiber_tracts_ids = (\n",
    "    region_map.find(\"fiber tracts\", attr=\"name\", with_descendants=True)\n",
    "    | region_map.find(\"grooves\", attr=\"name\", with_descendants=True)\n",
    "    | region_map.find(\"ventricular systems\", attr=\"name\", with_descendants=True)\n",
    ")\n",
    "hippocampus = (\n",
    "    region_map.find(\"Hippocampal region\", attr=\"name\", with_descendants=True)\n",
    ")\n",
    "hippocampal_formation = (\n",
    "    region_map.find(\"Hippocampal formation\", attr=\"name\", with_descendants=True)\n",
    ")\n",
    "thalamus = (\n",
    "    region_map.find(\"Thalamus\", attr=\"name\", with_descendants=True)\n",
    ")\n",
    "striatum = (\n",
    "    region_map.find(\"Striatum\", attr=\"name\", with_descendants=True)\n",
    ")\n",
    "VPL = (\n",
    "    region_map.find(\"Ventral posterolateral nucleus of the thalamus\", attr=\"name\", with_descendants=True)\n",
    ")\n",
    "LGd = (\n",
    "    region_map.find(\"Dorsal part of the lateral geniculate complex\", attr=\"name\", with_descendants=True)\n",
    ")\n",
    "VPM = (\n",
    "    region_map.find(\"Ventral posteromedial nucleus of the thalamus\", attr=\"name\", with_descendants=True)\n",
    ")\n",
    "MOB = (\n",
    "    region_map.find(\"Main olfactory bulb\", attr=\"name\", with_descendants=True)\n",
    ")\n",
    "\n",
    "#This cell will complement the two cells above\n",
    "Hindbrain = (\n",
    "    region_map.find(\"Hindbrain\", attr=\"name\", with_descendants=True)\n",
    ")\n",
    "Midbrain = (\n",
    "    region_map.find(\"Midbrain\", attr=\"name\", with_descendants=True)\n",
    ")\n",
    "Interbrain = (\n",
    "    region_map.find(\"Interbrain\", attr=\"name\", with_descendants=True)\n",
    ")\n",
    "Olfactoryareas = (\n",
    "    region_map.find(\"Olfactory areas\", attr=\"name\", with_descendants=True)\n",
    ")\n",
    "Corticalsubplate = (\n",
    "    region_map.find(\"Cortical subplate\", attr=\"name\", with_descendants=True)\n",
    ")\n",
    "Cerebralnuclei = (\n",
    "    region_map.find(\"Cerebral nuclei\", attr=\"name\", with_descendants=True)\n",
    ")\n",
    "cerebral_cortex = (\n",
    "    region_map.find(\"Cerebral cortex\", attr=\"name\", with_descendants=True)\n",
    ")\n",
    "wholebrain = (\n",
    "    region_map.find(\"root\", attr=\"name\", with_descendants=True)\n",
    ")\n",
    "\n",
    "#This is the final dictionary of all region names and their region ids\n",
    "areas = {\n",
    "    'wholebrain': wholebrain, 'Cerebral cortex': cerebral_cortex,\n",
    "    'isocortex': isocortex, 'cerebellum': cerebellum, 'fiber_tracts_ids': fiber_tracts_ids, \n",
    "    'hippocampus': hippocampus, 'hippocampal_formation':hippocampal_formation, \n",
    "    'thalamus': thalamus, 'striatum': striatum, 'VPL': VPL, 'LGd': LGd, 'VPM': VPM, 'MOB': MOB,\n",
    "    'Olfactory areas': Olfactoryareas, 'Cortical subplate': Corticalsubplate, \n",
    "    'Cerebral nuclei': Cerebralnuclei, 'Interbrain': Interbrain , 'Midbrain': Midbrain, \n",
    "    'Interbrain': Interbrain\n",
    "}\n",
    "\n",
    "areas_min = {\n",
    "    'wholebrain': wholebrain, 'Cerebral cortex': cerebral_cortex, 'cerebellum': cerebellum,\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3b565fe1-6013-48f9-a336-455566f2136d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regions _covered_ in the brain / total cells dict of df: 703\n",
      "Region was found, will remove: unassigned.\n",
      "For now we are removing the region unassigned as we cannot place it in the hierarchy.json system\n",
      "Region was found, will remove brain-unassigned.\n",
      "For now we are removing the region brain-unassigned as we cannot place it in the hierarchy.json system\n",
      "Remaining regions: 701\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(708, 19)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We have to filter unassigned regions since we don't know enough of them.\n",
    "\n",
    "regions = list(scaled_total_cells_local.keys())\n",
    "print(f'Regions _covered_ in the brain / total cells dict of df: {len(regions)}')\n",
    "# Assuming 'my_list' is your list\n",
    "if 'unassigned' in regions:\n",
    "    print(\"Region was found, will remove: unassigned.\")\n",
    "    regions.remove('unassigned')\n",
    "    print(\"For now we are removing the region unassigned as we cannot place it in the hierarchy.json system\")\n",
    "    \n",
    "if 'brainunassigned' in regions:\n",
    "    print(\"Region was found, will remove brain-unassigned.\")\n",
    "    regions.remove('brainunassigned')\n",
    "    print(\"For now we are removing the region brain-unassigned as we cannot place it in the hierarchy.json system\")\n",
    "\n",
    "if 'brain-unassigned' in regions:\n",
    "    print(\"Region was found, will remove brain-unassigned.\")\n",
    "    regions.remove('brain-unassigned')\n",
    "    print(\"For now we are removing the region brain-unassigned as we cannot place it in the hierarchy.json system\") \n",
    "    \n",
    "print(f\"Remaining regions: {len(regions)}\")\n",
    "region_info = parcellation_annotation[parcellation_annotation['cluster_as_filename'].isin(regions)]\n",
    "# region_info = parcellation_annotation[parcellation_annotation['parcellation_term_acronym'].isin(regions)]\n",
    "\n",
    "region_info.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "409e7430-31d0-4e04-a33c-60aa7b503edb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The brain area wholebrain has 5156 different cell types\n",
      "Total sum of neurons: 53,360,742\n",
      "The brain area Cerebral cortex has 1800 different cell types\n",
      "Total sum of neurons: 33,502,874\n",
      "The brain area cerebellum has 1116 different cell types\n",
      "Total sum of neurons: 3,939,848\n"
     ]
    }
   ],
   "source": [
    "#Next we can calculate total cell numbers overall and in specific regions\n",
    "\n",
    "scaled_total_cells_local_copy = copy.deepcopy(scaled_total_cells_local) \n",
    "ground_truth_cell_numbers = []\n",
    "\n",
    "for key, df in scaled_total_cells_local_copy.items():\n",
    "    scaled_total_cells_local_copy[key] = df[df.index.isin(neurontypes)]\n",
    "\n",
    "for key, value in areas_min.items():\n",
    "    \n",
    "    keys_to_drop = ['unassigned', 'brain-unassigned']\n",
    "    for region in regions:\n",
    "        \n",
    "        #filtered_data = region_info[(region_info['cluster_as_filename'] == region) &(region_info['parcellation_term_set_name'] == 'substructure')]\n",
    "        filtered_data = parcellation_annotation[(parcellation_annotation['cluster_as_filename'] == region) &(region_info['parcellation_term_set_name'] == 'substructure')]\n",
    "        id_ = filtered_data['label_numbers'].iloc[0]\n",
    "        \n",
    "        if int(id_) in value:\n",
    "            #print(region, id_, \"is in the set\")\n",
    "            None\n",
    "        else:\n",
    "            #print(id_, \"is not in the set\")\n",
    "            keys_to_drop.append(region)\n",
    "\n",
    "        #break    \n",
    "\n",
    "    # Create a new dictionary without the specified keys (all leaf regions and their cell types in 1 region)\n",
    "    scaled_total_cells_local_filtered = {key: value for key, value in scaled_total_cells_local_copy.items() if key not in keys_to_drop}\n",
    "\n",
    "    # Concatenate all DataFrames into a single DataFrame\n",
    "    concatenated_df = pd.concat(scaled_total_cells_local_filtered.values())\n",
    "\n",
    "    # Group by all columns except the 'total_cells' column and sum the values\n",
    "    summed_df = concatenated_df.groupby(concatenated_df.index).sum()\n",
    "    print(f\"The brain area {key} has {summed_df.shape[0]} different cell types\")\n",
    "    #print(\"Total sum of cells:\", '{:,.0f}'.format(summed_df['density_mm3'].sum()))\n",
    "    print(\"Total sum of neurons:\", '{:,.0f}'.format(summed_df['total_cellnumber'].sum()))\n",
    "    ground_truth_cell_numbers.append(summed_df['total_cellnumber'].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "442b92b3-292d-45c8-a02d-881a6798eef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#WE can store the values in a variable and get the scaling ratios\n",
    "mfish_ctx = ground_truth_cell_numbers[1]\n",
    "mfish_crb = ground_truth_cell_numbers[2]\n",
    "mfish_rest = ground_truth_cell_numbers[0] - mfish_ctx - mfish_crb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c5d31d7d-79cc-4ab7-8a3b-e5c15f23b2ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37.66369430556719, 1061.5918036629878, 103.31988184651408)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Scaling factors as percentage\n",
    "1/(mfish_ctx/total_ctx)*100, 1/(mfish_crb/total_crb)*100, 1/(mfish_rest/total_rest)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "77eb7cb9-b3bd-469d-8df9-ba451b47f75b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33502873.875372417, 12618420.0, 0.3766369430556719, 12618420.0)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mfish_ctx, total_ctx, 1/(mfish_ctx/total_ctx), mfish_ctx*(1/(mfish_ctx/total_ctx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "68ee24e9-c5ab-41f0-b722-cd9429ec1e40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fa corpus callosum, anterior forceps\n",
      "icp inferior cerebellar peduncle\n",
      "sV sensory root of the trigeminal nerve\n",
      "scp superior cerebelar peduncles\n",
      "st stria terminalis\n",
      "309 54 340\n"
     ]
    }
   ],
   "source": [
    "#Sanity check\n",
    "#no CTX or CRB keys should be printed. Only regions with multiple solutions, which is taken care of elsewhere\n",
    "\n",
    "ctx_keys = []\n",
    "crb_keys = []\n",
    "else_keys = []\n",
    "for key in combined_result_dataframes.keys():\n",
    "    cluster_as_filename = parcellation_annotation[parcellation_annotation['cluster_as_filename'] == key]\n",
    "    cluster = cluster_as_filename[cluster_as_filename['parcellation_term_set_name'] == 'substructure']\n",
    "    #This != part is for ambiguous regions:\n",
    "    if cluster.shape[0] != 1:\n",
    "        print( key, cluster['parcellation_term_name'].values[0] )\n",
    "        for key_name in cluster['cluster_as_filename'].values:\n",
    "            # Add the element to else_keys list\n",
    "            else_keys.append(key_name)\n",
    "    elif cluster['label_numbers'].iloc[0] in cerebral_cortex:\n",
    "        ctx_keys.append(cluster['cluster_as_filename'].iloc[0])\n",
    "    elif cluster['label_numbers'].iloc[0] in cerebellum:\n",
    "        crb_keys.append(cluster['cluster_as_filename'].iloc[0])\n",
    "    else:\n",
    "        else_keys.append(cluster['cluster_as_filename'].iloc[0])\n",
    "\n",
    "#remove duplicates if there's any (in else there is)\n",
    "else_keys = list(dict.fromkeys(else_keys))\n",
    "crb_keys = list(dict.fromkeys(crb_keys))\n",
    "ctx_keys = list(dict.fromkeys(ctx_keys))\n",
    "\n",
    "print(len(ctx_keys), len(crb_keys), len(else_keys), )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08fbcb62-3343-4125-a5d4-5608f6e41e2a",
   "metadata": {},
   "source": [
    "Scaling: We will scale the regions one by one according to their anatomical positions:\n",
    "\n",
    "- If the region was scaled earlier in the previous section we should not scale it anymore\n",
    "- In the CTX we can scale with the cortical scaling ratio\n",
    "- IN the CRB with the cerebellar scaling ratio\n",
    "- Everywhere else with the residual scaling ratio\n",
    "- Glia can be scaled by 1x (change)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a0326f05-2586-4701-a40a-3f8dca099edb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2.6550767746970236, 0.09419816510918158, 0.9678679283485253)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mfish_ctx/total_ctx, mfish_crb/total_crb, mfish_rest/total_rest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60d8fe49-60ba-42ba-aa02-61104436498c",
   "metadata": {},
   "source": [
    "Global scaling factors from literature will be in effect:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "45d7711d-6ee6-4e4e-a9e9-82466c207cbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 556 ms, sys: 2.88 ms, total: 559 ms\n",
      "Wall time: 557 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#Scaling will take place\n",
    "combined_result_dataframes_copy = copy.deepcopy(scaled_combined_result_dataframes)\n",
    "# del scaled_combined_result_dataframes\n",
    "globally_scaled_combined_result_dfs = {}\n",
    "\n",
    "#Do the scaling: CTX: neurons only, CRB: EXC only, ELSE: neuron only\n",
    "for key, df in combined_result_dataframes_copy.items():\n",
    "    #Leave those regions which we have scaled already as they are\n",
    "    if key in concatenated_result:\n",
    "        globally_scaled_combined_result_dfs[key] = df\n",
    "       \n",
    "    #Scale only the neurons and glia:\n",
    "    elif key in ctx_keys:\n",
    "        # Select rows where the value is in neurontypes\n",
    "        mask = df.index.isin(neurontypes)\n",
    "        \n",
    "        # Divide only selected rows by scaling factor for CTX Neuron\n",
    "        df.loc[mask, 'density_mm3'] /= (mfish_ctx/total_ctx)\n",
    "        globally_scaled_combined_result_dfs[key] = df\n",
    "        del df, mask\n",
    "        \n",
    "    elif key in crb_keys:\n",
    "        # Select rows where the value is in  exc types\n",
    "        mask = df.index.isin(exctypes)\n",
    "        # Select rows where the value is in neuron+glia types (this was an attempt to see what glia numbers would be if changed)\n",
    "        # combined = np.concatenate((exctypes, glia))\n",
    "        # mask = df.index.isin(combined)\n",
    "        \n",
    "        # Divide only selected rows by scaling factor for CB EXC\n",
    "        df.loc[mask, 'density_mm3'] /= (mfish_crb/total_crb)\n",
    "        globally_scaled_combined_result_dfs[key] = df        \n",
    "        #print(df)\n",
    "        del df, mask\n",
    "    \n",
    "    elif key in else_keys:\n",
    "        # Select rows where the value is in neurontypes\n",
    "        mask = df.index.isin(neurontypes)\n",
    "        \n",
    "        # Divide only selected rows by scaling factor for REST\n",
    "        df.loc[mask, 'density_mm3'] /= (mfish_rest/total_rest)\n",
    "        globally_scaled_combined_result_dfs[key] = df        \n",
    "        del df, mask\n",
    "\n",
    "    else:\n",
    "        print(key, \"is an Issue!\")\n",
    "\n",
    "\n",
    "# # Check if multiplication took place\n",
    "# for key, df in combined_result_dataframes_copy.items():\n",
    "#     if key in ctx_keys:\n",
    "#         print(f'Original value for key {key}:')\n",
    "#         print(df['density_mm3'])\n",
    "        \n",
    "# for key, df in scaled_combined_result_dataframes.items():\n",
    "#     if key in ctx_keys:\n",
    "#         print(f'Copied value for key {key}:')\n",
    "#         print(df['density_mm3'])\n",
    "\n",
    "#del combined_result_dataframes_copy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e4aac1-9ea4-48d6-bacf-5832dcb86f52",
   "metadata": {},
   "source": [
    "# Additional scaling factors to compensate local overwrite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8f002860-c107-4616-8d10-2e129db81a37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.33 s, sys: 12.7 ms, total: 1.34 s\n",
      "Wall time: 1.33 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#These numbers come from checking total values after transplant and loop scaling!\n",
    "sc_factor_glia = 0.75\n",
    "sc_factor_inh = 1.9\n",
    "sc_factor_exc = 0.75\n",
    "\n",
    "#Scaling will take place\n",
    "combined_result_dataframes_copy = copy.deepcopy(globally_scaled_combined_result_dfs)\n",
    "# del scaled_combined_result_dataframes\n",
    "globally_scaled_combined_result_dfs_2 = {}\n",
    "\n",
    "#Do the scaling:\n",
    "for key, df in combined_result_dataframes_copy.items():\n",
    "    #Leave those regions which we have been transplanted (local) as they are, except for GLIA:\n",
    "    if key in concatenated_result:       \n",
    "\n",
    "        # Select rows where the value is in glia\n",
    "        mask = df.index.isin(glia)\n",
    "        \n",
    "        # Divide only selected rows by scaling factor for CTX\n",
    "        df.loc[mask, 'density_mm3'] /= sc_factor_glia #Change later\n",
    "        globally_scaled_combined_result_dfs_2[key] = df\n",
    "        \n",
    "    #Scale only in the CTX:\n",
    "    elif key in ctx_keys:     \n",
    "        # Select rows where the value is in glia\n",
    "        mask = df.index.isin(glia)\n",
    "        \n",
    "        # Divide only selected rows by scaling factor for CTX GLIA\n",
    "        df.loc[mask, 'density_mm3'] /= sc_factor_glia #Change later\n",
    "        globally_scaled_combined_result_dfs_2[key] = df\n",
    "        del mask\n",
    "\n",
    "        # Select rows where the value is in EXC\n",
    "        mask = df.index.isin(exctypes)\n",
    "        \n",
    "        # Divide only selected rows by scaling factor for CTX EXC\n",
    "        df.loc[mask, 'density_mm3'] /= sc_factor_exc #Change later\n",
    "        globally_scaled_combined_result_dfs_2[key] = df\n",
    "        del mask        \n",
    "        \n",
    "        # Select rows where the value is in  inh types\n",
    "        mask = df.index.isin(inhtypes)\n",
    "        \n",
    "        # Divide only selected rows by scaling factor for CTX INH\n",
    "        df.loc[mask, 'density_mm3'] /= sc_factor_inh\n",
    "        globally_scaled_combined_result_dfs_2[key] = df        \n",
    "        #print(df)\n",
    "        del df, mask\n",
    "\n",
    "    #Scale only in the CRB:\n",
    "    elif key in crb_keys:\n",
    "        # Select rows where the value is in glia\n",
    "        mask = df.index.isin(glia)\n",
    "        \n",
    "        # Divide only selected rows by scaling factor for CB GLIA\n",
    "        df.loc[mask, 'density_mm3'] /= sc_factor_glia #Change later\n",
    "        globally_scaled_combined_result_dfs_2[key] = df\n",
    "        del mask\n",
    "\n",
    "        # Select rows where the value is in EXC\n",
    "        mask = df.index.isin(exctypes)\n",
    "        \n",
    "        # Divide only selected rows by scaling factor for CRB EXC\n",
    "        df.loc[mask, 'density_mm3'] /= sc_factor_exc #Change later\n",
    "        globally_scaled_combined_result_dfs_2[key] = df\n",
    "        del mask   \n",
    "        \n",
    "        # Select rows where the value is in  inh types\n",
    "        mask = df.index.isin(inhtypes)\n",
    "        \n",
    "        # Divide only selected rows by scaling factor for CB INH\n",
    "        df.loc[mask, 'density_mm3'] /= sc_factor_inh\n",
    "        globally_scaled_combined_result_dfs_2[key] = df        \n",
    "        #print(df)\n",
    "        del df, mask\n",
    "\n",
    "    #Scale only in the REST of the brain:\n",
    "    elif key in else_keys:\n",
    "        # Select rows where the value is in glia\n",
    "        mask = df.index.isin(glia)\n",
    "        \n",
    "        # Divide only selected rows by scaling factor for REST GLIA\n",
    "        df.loc[mask, 'density_mm3'] /= sc_factor_glia #Change later\n",
    "        globally_scaled_combined_result_dfs_2[key] = df\n",
    "        del mask\n",
    "\n",
    "        # Select rows where the value is in EXC\n",
    "        mask = df.index.isin(exctypes)\n",
    "        \n",
    "        # Divide only selected rows by scaling factor for REST EXC\n",
    "        df.loc[mask, 'density_mm3'] /= sc_factor_exc #Change later\n",
    "        globally_scaled_combined_result_dfs_2[key] = df\n",
    "        del mask           \n",
    "\n",
    "        # Select rows where the value is in  inh types\n",
    "        mask = df.index.isin(inhtypes)\n",
    "        \n",
    "        # Divide only selected rows by scaling factor for REST INH\n",
    "        df.loc[mask, 'density_mm3'] /= sc_factor_inh\n",
    "        globally_scaled_combined_result_dfs_2[key] = df        \n",
    "        #print(df)\n",
    "        del df, mask\n",
    "\n",
    "    else:\n",
    "        print(key, \"is an Issue!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "73341b11-b827-48c0-87b8-f40b17ea0a54",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved here: /gpfs/bbp.cscs.ch/data/project/proj84/csaba/aibs_10x_mouse_wholebrain/results/density_calculations/\n"
     ]
    }
   ],
   "source": [
    "# Assuming 'globally_scaled_combined_result_dfs_2' is your dictionary of DataFrames\n",
    "with open(f'{root_folder}scaled_densities_new.pickle', 'wb') as f:\n",
    "    pickle.dump(globally_scaled_combined_result_dfs_2, f)\n",
    "\n",
    "print(f\"Saved here: {root_folder}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6587a373-0cf5-4ad1-96b3-b5194a6e805d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>density_mm3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cluster</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0023 L5/6 IT TPE-ENT Glut_1</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0093 L4/5 IT CTX Glut_4</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0150 L2/3 IT PIR-ENTl Glut_3</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0205 MEA Slc17a7 Glut_2</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0207 MEA Slc17a7 Glut_2</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5309 Endo NN_1</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5310 Endo NN_1</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5311 Endo NN_1</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5312 Microglia NN_1</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5314 BAM NN_1</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>412 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              density_mm3\n",
       "cluster                                  \n",
       "0023 L5/6 IT TPE-ENT Glut_1          True\n",
       "0093 L4/5 IT CTX Glut_4              True\n",
       "0150 L2/3 IT PIR-ENTl Glut_3         True\n",
       "0205 MEA Slc17a7 Glut_2              True\n",
       "0207 MEA Slc17a7 Glut_2              True\n",
       "...                                   ...\n",
       "5309 Endo NN_1                       True\n",
       "5310 Endo NN_1                       True\n",
       "5311 Endo NN_1                       True\n",
       "5312 Microglia NN_1                 False\n",
       "5314 BAM NN_1                        True\n",
       "\n",
       "[412 rows x 1 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "globally_scaled_combined_result_dfs['AAA'] == globally_scaled_combined_result_dfs_2['AAA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e0bda656-26d3-44a5-b312-1e67b0215221",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>density_mm3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cluster</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5186 CBX Golgi Gly-Gaba_1</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5198 CB Granule Glut_1</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5200 CB Granule Glut_2</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5201 CB Granule Glut_2</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5202 DCO UBC Glut_1</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5204 DCO UBC Glut_1</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5205 DCO UBC Glut_1</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5207 Astro-CB NN_1</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5208 Astro-NT NN_1</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5209 Astro-NT NN_1</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5210 Astro-NT NN_1</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5217 Astro-NT NN_2</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5219 Astro-TE NN_1</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5224 Astro-TE NN_3</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5253 Ependymal NN_1</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5256 Ependymal NN_1</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5258 Ependymal NN_1</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5264 CHOR NN_1</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5265 CHOR NN_1</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5271 OPC NN_2</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5276 COP NN_1</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5284 MOL NN_4</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5285 MOL NN_4</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5286 MOL NN_4</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5298 VLMC NN_1</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5299 VLMC NN_1</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5301 VLMC NN_2</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5302 VLMC NN_3</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5304 Peri NN_1</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5307 SMC NN_1</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5309 Endo NN_1</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5310 Endo NN_1</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5311 Endo NN_1</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5312 Microglia NN_1</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5314 BAM NN_1</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           density_mm3\n",
       "cluster                               \n",
       "5186 CBX Golgi Gly-Gaba_1        False\n",
       "5198 CB Granule Glut_1           False\n",
       "5200 CB Granule Glut_2           False\n",
       "5201 CB Granule Glut_2           False\n",
       "5202 DCO UBC Glut_1              False\n",
       "5204 DCO UBC Glut_1              False\n",
       "5205 DCO UBC Glut_1              False\n",
       "5207 Astro-CB NN_1               False\n",
       "5208 Astro-NT NN_1               False\n",
       "5209 Astro-NT NN_1               False\n",
       "5210 Astro-NT NN_1               False\n",
       "5217 Astro-NT NN_2               False\n",
       "5219 Astro-TE NN_1               False\n",
       "5224 Astro-TE NN_3               False\n",
       "5253 Ependymal NN_1               True\n",
       "5256 Ependymal NN_1               True\n",
       "5258 Ependymal NN_1               True\n",
       "5264 CHOR NN_1                    True\n",
       "5265 CHOR NN_1                    True\n",
       "5271 OPC NN_2                    False\n",
       "5276 COP NN_1                    False\n",
       "5284 MOL NN_4                    False\n",
       "5285 MOL NN_4                    False\n",
       "5286 MOL NN_4                    False\n",
       "5298 VLMC NN_1                    True\n",
       "5299 VLMC NN_1                    True\n",
       "5301 VLMC NN_2                    True\n",
       "5302 VLMC NN_3                    True\n",
       "5304 Peri NN_1                    True\n",
       "5307 SMC NN_1                     True\n",
       "5309 Endo NN_1                    True\n",
       "5310 Endo NN_1                    True\n",
       "5311 Endo NN_1                    True\n",
       "5312 Microglia NN_1              False\n",
       "5314 BAM NN_1                     True"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "globally_scaled_combined_result_dfs['LINGgranularlayer'] == globally_scaled_combined_result_dfs_2['LINGgranularlayer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "99913f90-6b53-4f0d-af27-1b8dcb8ef9dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "703"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(globally_scaled_combined_result_dfs_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c679a9b2-077d-432c-a77e-eb9491dee7ab",
   "metadata": {},
   "source": [
    "We have to change back the df to contain cell types as keys:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ff9c9778-df6b-4986-bf93-7a135bb69c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruct_original_dataframes(combined_dataframes):\n",
    "    \"\"\"\n",
    "    Reconstructs the original dictionary of dataframes (result_dataframes)\n",
    "    from the transformed combined_dataframes.\n",
    "\n",
    "    Parameters:\n",
    "    - combined_dataframes: dict, where keys are clusters and values are dataframes\n",
    "      of brain region densities.\n",
    "\n",
    "    Returns:\n",
    "    - result_dataframes: dict of dataframes where keys are brain region prefixes\n",
    "      and values are dataframes of cell-type densities.\n",
    "    \"\"\"\n",
    "    result_dataframes = {}\n",
    "\n",
    "    # Iterate over each cluster and its associated dataframe\n",
    "    for cluster, df in combined_dataframes.items():\n",
    "        # For each row in the dataframe, assign the data to the correct prefix\n",
    "        for prefix, row in df.iterrows():\n",
    "            if prefix not in result_dataframes:\n",
    "                result_dataframes[prefix] = pd.DataFrame(columns=df.columns)\n",
    "\n",
    "            # Add the row to the corresponding prefix dataframe\n",
    "            result_dataframes[prefix].loc[cluster] = row\n",
    "\n",
    "    return result_dataframes\n",
    "\n",
    "celltypes_as_keys = reconstruct_original_dataframes(globally_scaled_combined_result_dfs_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8da8fa6-61e1-49d0-9799-04ccecb7482c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "99ae70a5-9219-44f0-a66e-3929383270ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/gpfs/bbp.cscs.ch/data/project/proj84/csaba/aibs_10x_mouse_wholebrain/results/density_calculations/scaled_total_neuron_densities.nrrd\n",
      "/gpfs/bbp.cscs.ch/data/project/proj84/csaba/aibs_10x_mouse_wholebrain/results/density_calculations/scaled_total_excitatory_densities.nrrd\n",
      "/gpfs/bbp.cscs.ch/data/project/proj84/csaba/aibs_10x_mouse_wholebrain/results/density_calculations/scaled_total_inhibitory_densities.nrrd\n",
      "/gpfs/bbp.cscs.ch/data/project/proj84/csaba/aibs_10x_mouse_wholebrain/results/density_calculations/scaled_total_astrotypes_densities.nrrd\n",
      "/gpfs/bbp.cscs.ch/data/project/proj84/csaba/aibs_10x_mouse_wholebrain/results/density_calculations/scaled_total_microglia_densities.nrrd\n",
      "/gpfs/bbp.cscs.ch/data/project/proj84/csaba/aibs_10x_mouse_wholebrain/results/density_calculations/scaled_total_oligocyte_densities.nrrd\n",
      "/gpfs/bbp.cscs.ch/data/project/proj84/csaba/aibs_10x_mouse_wholebrain/results/density_calculations/scaled_total_glia_densities.nrrd\n",
      "/gpfs/bbp.cscs.ch/data/project/proj84/csaba/aibs_10x_mouse_wholebrain/results/density_calculations/scaled_total_excinh_densities.nrrd\n",
      "/gpfs/bbp.cscs.ch/data/project/proj84/csaba/aibs_10x_mouse_wholebrain/results/density_calculations/scaled_total_celltypes_densities.nrrd\n",
      "/gpfs/bbp.cscs.ch/data/project/proj84/csaba/aibs_10x_mouse_wholebrain/results/density_calculations/scaled_total_nonneuron_densities.nrrd\n",
      "CPU times: user 1min 5s, sys: 6.3 s, total: 1min 12s\n",
      "Wall time: 9min 57s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#from multiprocessing import Pool\n",
    "\n",
    "def process_type(types, file_name):\n",
    "    # Filter DataFrames based on types\n",
    "    filtered_dataframes = {key: value for key, value in celltypes_as_keys.items() if key in types}\n",
    "    \n",
    "    # Combine filtered DataFrames\n",
    "    combined_df = pd.concat(filtered_dataframes.values())\n",
    "    \n",
    "    # Sum the combined DataFrame by index\n",
    "    summed_df = combined_df.groupby(combined_df.index).sum()\n",
    "    \n",
    "    # Validate result\n",
    "    result = nrrd_for_validation(summed_df, parcellation_annotation, CCFv3)\n",
    "    \n",
    "    # Clean up\n",
    "    del combined_df, summed_df, filtered_dataframes\n",
    "\n",
    "    return (result, file_name)\n",
    "\n",
    "def main():\n",
    "    # Define the parameters for each process\n",
    "    tasks = [\n",
    "        (neurontypes, \"scaled_total_neuron_densities\"),\n",
    "        (exctypes, \"scaled_total_excitatory_densities\"),\n",
    "        (inhtypes, \"scaled_total_inhibitory_densities\"),\n",
    "        (astrotypes, \"scaled_total_astrotypes_densities\"),\n",
    "        (microglia, \"scaled_total_microglia_densities\"),\n",
    "        (oligos, \"scaled_total_oligocyte_densities\"),\n",
    "        (glia, \"scaled_total_glia_densities\"),\n",
    "        (exci_inhib_sum, \"scaled_total_excinh_densities\"),\n",
    "        (celltypes, \"scaled_total_celltypes_densities\"),\n",
    "        (nonneurontypes, \"scaled_total_nonneuron_densities\")\n",
    "    ]\n",
    "    \n",
    "    # Create a multiprocessing Pool\n",
    "    with mp.Pool(processes=mp.cpu_count()) as pool:\n",
    "        results = pool.starmap(process_type, tasks)\n",
    "    \n",
    "    # Sequentially write the .nrrd files to avoid concurrent writes\n",
    "    for result, file_name in results:\n",
    "        nrrd.write(f\"{root_folder}{file_name}.nrrd\", result)\n",
    "        print(f\"{root_folder}{file_name}.nrrd\")\n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca1a0fba-97da-46b7-a3d4-78a98d5e352c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "af9dfd59-54cf-4f12-9211-a04000658ea5",
   "metadata": {},
   "source": [
    "# Test results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3d367e2c-4d1f-4bd1-96ca-3f4e0f9c1b9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/gpfs/bbp.cscs.ch/data/project/proj84/csaba/aibs_10x_mouse_wholebrain/results/density_calculations/'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root_folder3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "616226dc-552c-4b9f-939f-fea3f8bff851",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pickle file.\n",
      "Loaded pickle file.\n"
     ]
    }
   ],
   "source": [
    "file = os.path.join( root_folder, 'scaled_densities_local.pickle' )\n",
    "\n",
    "#Load region id volumes from volume_calc_from_template.ipynb\n",
    "with open(file, 'rb') as pickle_file:\n",
    "    test = pickle.load(pickle_file)\n",
    "print(\"Loaded pickle file.\")\n",
    "\n",
    "root_folder3 = '/gpfs/bbp.cscs.ch/data/project/proj84/csaba/aibs_10x_mouse_wholebrain/results/density_calculations/'\n",
    "file = os.path.join( root_folder3, 'scaled_densities_new.pickle' )\n",
    "\n",
    "#Load region id volumes from volume_calc_from_template.ipynb\n",
    "with open(file, 'rb') as pickle_file:\n",
    "    scaled_densities_new = pickle.load(pickle_file)\n",
    "print(\"Loaded pickle file.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "500ae4be-7ed3-488e-9839-92ba3c9f389c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(703, 703)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(scaled_densities_new), len(test)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6ec31c69-2585-427a-b340-d015aafea857",
   "metadata": {},
   "source": [
    "scaled_densities_new == test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ff350765-b6a5-4ba9-8795-507137a9e42b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys unique to scaled_densities_new: set()\n",
      "Keys unique to test: set()\n"
     ]
    }
   ],
   "source": [
    "# Get the keys of both dictionaries as sets\n",
    "keys_scaled_densities_new = set(scaled_densities_new.keys())\n",
    "keys_test = set(test.keys())\n",
    "\n",
    "# Find keys unique to each dictionary\n",
    "unique_to_scaled_densities_new = keys_scaled_densities_new - keys_test\n",
    "unique_to_test = keys_test - keys_scaled_densities_new\n",
    "\n",
    "# Print the unique keys in both dictionaries\n",
    "print(\"Keys unique to scaled_densities_new:\", unique_to_scaled_densities_new)\n",
    "print(\"Keys unique to test:\", unique_to_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "990d7aaa-e96f-4b43-8c87-5d87b6bc5b7d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>density_mm3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cluster</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4196 NLL-SOC Spp1 Glut_2</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4198 PG-TRN-LRN Fat2 Glut_1</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4482 MV-SPIV Phox2b Ebf3 Lbx1 Glut_1</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4505 MV-SPIV Zic4 Neurod2 Glut_3</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4516 MV-SPIV Zic4 Neurod2 Glut_5</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4521 CBN Neurod2 Pvalb Glut_1</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4522 CBN Neurod2 Pvalb Glut_1</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4812 POR Spp1 Gly-Gaba_1</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4899 MY Lhx1 Gly-Gaba_3</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4935 MV-SPIV-PRP Dmbx1 Gly-Gaba_1</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4936 MV-SPIV-PRP Dmbx1 Gly-Gaba_1</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4941 MV-SPIV-PRP Dmbx1 Gly-Gaba_1</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4981 PAS-MV Ebf2 Gly-Gaba_1</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997 MV Pax6 Gly-Gaba_1</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5176 DCO Il22 Gly-Gaba_3</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5177 CB PLI Gly-Gaba_1</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5182 CB PLI Gly-Gaba_2</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5183 CB PLI Gly-Gaba_3</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5208 Astro-NT NN_1</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5210 Astro-NT NN_1</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5212 Astro-NT NN_1</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5216 Astro-NT NN_2</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5217 Astro-NT NN_2</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5269 OPC NN_1</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5271 OPC NN_2</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5279 NFOL NN_2</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5284 MOL NN_4</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5285 MOL NN_4</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5286 MOL NN_4</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5287 MOL NN_4</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5299 VLMC NN_1</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5301 VLMC NN_2</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5304 Peri NN_1</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5307 SMC NN_1</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5309 Endo NN_1</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5310 Endo NN_1</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5311 Endo NN_1</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5312 Microglia NN_1</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      density_mm3\n",
       "cluster                                          \n",
       "4196 NLL-SOC Spp1 Glut_2                    False\n",
       "4198 PG-TRN-LRN Fat2 Glut_1                 False\n",
       "4482 MV-SPIV Phox2b Ebf3 Lbx1 Glut_1        False\n",
       "4505 MV-SPIV Zic4 Neurod2 Glut_3            False\n",
       "4516 MV-SPIV Zic4 Neurod2 Glut_5            False\n",
       "4521 CBN Neurod2 Pvalb Glut_1               False\n",
       "4522 CBN Neurod2 Pvalb Glut_1               False\n",
       "4812 POR Spp1 Gly-Gaba_1                    False\n",
       "4899 MY Lhx1 Gly-Gaba_3                     False\n",
       "4935 MV-SPIV-PRP Dmbx1 Gly-Gaba_1           False\n",
       "4936 MV-SPIV-PRP Dmbx1 Gly-Gaba_1           False\n",
       "4941 MV-SPIV-PRP Dmbx1 Gly-Gaba_1           False\n",
       "4981 PAS-MV Ebf2 Gly-Gaba_1                 False\n",
       "4997 MV Pax6 Gly-Gaba_1                     False\n",
       "5176 DCO Il22 Gly-Gaba_3                    False\n",
       "5177 CB PLI Gly-Gaba_1                      False\n",
       "5182 CB PLI Gly-Gaba_2                      False\n",
       "5183 CB PLI Gly-Gaba_3                      False\n",
       "5208 Astro-NT NN_1                          False\n",
       "5210 Astro-NT NN_1                          False\n",
       "5212 Astro-NT NN_1                          False\n",
       "5216 Astro-NT NN_2                          False\n",
       "5217 Astro-NT NN_2                          False\n",
       "5269 OPC NN_1                               False\n",
       "5271 OPC NN_2                               False\n",
       "5279 NFOL NN_2                              False\n",
       "5284 MOL NN_4                               False\n",
       "5285 MOL NN_4                               False\n",
       "5286 MOL NN_4                               False\n",
       "5287 MOL NN_4                               False\n",
       "5299 VLMC NN_1                               True\n",
       "5301 VLMC NN_2                               True\n",
       "5304 Peri NN_1                               True\n",
       "5307 SMC NN_1                                True\n",
       "5309 Endo NN_1                               True\n",
       "5310 Endo NN_1                               True\n",
       "5311 Endo NN_1                               True\n",
       "5312 Microglia NN_1                         False"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_densities_new[\"y\"] == test[\"y\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1457007-4666-4bfb-b3fc-fedda2de5be7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f116b5fb-121b-477e-a86f-063ef7fcb4fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8818c46b-2ef0-47d8-b9b3-ae145915fd8e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
